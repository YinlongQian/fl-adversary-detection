{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "adv_handling.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVJsctDXOv9g"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "from data_utils import CustomImageDataset, split_image_data\n",
        "from data_utils import get_default_data_transforms\n",
        "from models import ConvNet\n",
        "from fl_devices import Server, Client\n",
        "from helper import ExperimentLogger, display_train_stats\n",
        "\n",
        "from sklearn.cluster import AgglomerativeClustering, DBSCAN\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr7jG9NfOv9i"
      },
      "source": [
        "# helper functions\n",
        "\n",
        "# feature_matrix:\n",
        "# each row is flatten dWs from a client\n",
        "# helper functions\n",
        "\n",
        "# detect_adv_idx: adverary indices detected by server\n",
        "# gt_adv_idx: ground-truth indices\n",
        "def check_detect(detect_adv_idx, gt_adv_idx):\n",
        "    intersection = [idx for idx in gt_adv_idx if idx in detect_adv_idx]\n",
        "    if len(intersection) > 0:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "# feature_matrix:\n",
        "# each row is flatten dWs from a client\n",
        "def generate_feature_matrix(dW_dicts):\n",
        "    with torch.no_grad():\n",
        "        rows = []\n",
        "        \n",
        "        for dW_dict in dW_dicts:\n",
        "            row = torch.empty(0).to(device)\n",
        "            for key, value in dW_dict.items():\n",
        "                row = torch.cat((row, value.flatten()), 0)\n",
        "            rows.append(row)\n",
        "            \n",
        "        matrix = torch.stack(rows, 0)\n",
        "        if device is \"cpu\":\n",
        "            return matrix.numpy()\n",
        "        else:\n",
        "            return matrix.cpu().numpy()\n",
        "        \n",
        "def print_labels(labels):\n",
        "    string = []\n",
        "    for idx, label in enumerate(labels):\n",
        "        string.append(str(idx)+': '+str(label))\n",
        "    print('\\t'.join(string))\n",
        "    \n",
        "def print_outliers(labels):\n",
        "    outlier_idx = np.argwhere(labels == -1).flatten()\n",
        "    print(outlier_idx)\n",
        "    \n",
        "def print_distance(feature_matrix, metric):\n",
        "    distance = pairwise_distances(feature_matrix,metric=metirc)\n",
        "    return distance \n",
        "\n",
        "def handle_adversary(adv_idx, handle, weights, reg_factor):\n",
        "    if handle == None:\n",
        "        return weights\n",
        "    elif handle == 'remove':\n",
        "        weights[adv_idx] = 0\n",
        "        return weights \n",
        "    elif handle == 'reg':\n",
        "        weights[adv_idx] = weights[adv_idx] * reg_factor\n",
        "        return weights\n",
        "    return weights"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70UGDklQSZFj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "05b756c4-9962-4e20-f572-ab734ef70d31"
      },
      "source": [
        "# hyperparameters\r\n",
        "N_CLIENT = 25\r\n",
        "N_ADV_RANDOM = 3\r\n",
        "N_ADV_OPP = 0\r\n",
        "N_ADV_SWAP = 0\r\n",
        "\r\n",
        "# hyperparemeters\r\n",
        "TOTAL_TRIAL = 1\r\n",
        "TOTAL_ROUND = 30\r\n",
        "DETECT_ROUND = 10\r\n",
        "\r\n",
        "ADV_HANDLE = [None, 'remove', 'reg']\r\n",
        "\r\n",
        "esp = 0.8\r\n",
        "min_samples =2\r\n",
        "reg_factor = 0.1\r\n",
        "metric = 'cosine'\r\n",
        "cfl_stats = ExperimentLogger()\r\n",
        "model_performance = defaultdict(lambda: [None] * TOTAL_TRIAL)\r\n",
        "for handle in ADV_HANDLE:\r\n",
        "  for trial in range(TOTAL_TRIAL):\r\n",
        "    data = datasets.MNIST(root='./',download=True)\r\n",
        "    train_frac = 0.2\r\n",
        "    test_frac = 0.2 \r\n",
        "    train_num = int(train_frac * len(data))\r\n",
        "    test_num = int(test_frac * len(data))\r\n",
        "    idcs = np.random.permutation(len(data))\r\n",
        "    train_idcs, test_idcs = idcs[:train_num], idcs[train_num:train_num + test_num]\r\n",
        "    train_labels = data.train_labels.numpy()\r\n",
        "    clients_split = split_image_data(data.train_data[train_idcs], train_labels[train_idcs], n_clients=N_CLIENT, classes_per_client=5,balancedness=1)\r\n",
        "    train_trans, val_trans = get_default_data_transforms(\"EMNIST\")\r\n",
        "    client_data = [CustomImageDataset(clients_split[i][0].to(torch.float32), clients_split[i][1],transforms=train_trans ) for i in range(len(clients_split))]\r\n",
        "\r\n",
        "    test_data = data.test_data[train_num:train_num+test_num]\r\n",
        "    test_labels = train_labels[train_num:train_num+test_num]\r\n",
        "    test_data = CustomImageDataset(test_data.to(torch.float32), test_labels, transforms=val_trans)\r\n",
        "\r\n",
        "    # Assign client modes\r\n",
        "    clients = [Client(ConvNet, lambda x : torch.optim.SGD(x, lr=0.1, momentum=0.9), client_data[i], idnum=i) \r\n",
        "              for i, dat in enumerate(client_data)]\r\n",
        "    client_indx = np.random.permutation(len(clients))\r\n",
        "    offset = 0\r\n",
        "    adv_random = client_indx[0:N_ADV_RANDOM]\r\n",
        "    offset += N_ADV_RANDOM\r\n",
        "    adv_opp = client_indx[offset:offset + N_ADV_OPP]\r\n",
        "    offset += N_ADV_OPP\r\n",
        "    adv_swap = client_indx[offset:offset+N_ADV_SWAP]\r\n",
        "    offset += N_ADV_SWAP\r\n",
        "    adv_idx = np.concatenate((adv_random,adv_opp,adv_swap)).tolist()\r\n",
        "    for i in adv_random:\r\n",
        "      clients[i].client_mode = 'random'\r\n",
        "\r\n",
        "    for i in adv_opp:\r\n",
        "      clients[i].client_mode = 'opposite'\r\n",
        "\r\n",
        "    for i in adv_swap:\r\n",
        "      clients[i].client_mode = 'swap'\r\n",
        "\r\n",
        "    # print out each client and its mode\r\n",
        "    for idx, client in enumerate(clients):\r\n",
        "      print('{}: {}'.format(idx, client.client_mode))\r\n",
        "\r\n",
        "    server = Server(ConvNet, test_data)\r\n",
        "    weights = np.ones(len(clients))\r\n",
        "    for round in range(TOTAL_ROUND):\r\n",
        "      if round == 0:\r\n",
        "        for client in clients:\r\n",
        "          client.synchronize_with_server(server)\r\n",
        "      \r\n",
        "      \r\n",
        "      participating_clients = server.select_clients(clients, frac=1.0)\r\n",
        "\r\n",
        "      for client in participating_clients:\r\n",
        "          train_stats = client.compute_weight_update(epochs=1)\r\n",
        "          client.reset()\r\n",
        "        \r\n",
        "      if round + 1 == DETECT_ROUND:\r\n",
        "          # generate feature matrix for clustering\r\n",
        "          client_dW_dicts = [client.dW for client in clients]\r\n",
        "          feature_matrix = generate_feature_matrix(client_dW_dicts)\r\n",
        "\r\n",
        "          # detect adversary using clustering\r\n",
        "          clustering_label = server.detect_adversary(feature_matrix, esp, min_samples, metric)\r\n",
        "          adv_idx_label = np.argwhere(clustering_label == -1).flatten()\r\n",
        "\r\n",
        "          # update clients by handling adversary detected\r\n",
        "          weights = handle_adversary(adv_idx_label, handle, weights,reg_factor)\r\n",
        "\r\n",
        "      # aggregate weight updates; copy new weights to clients\r\n",
        "      server.aggregate_wieght_updates_weight(clients, weights)\r\n",
        "      server.copy_weights(clients)\r\n",
        "                \r\n",
        "    # evaluate model performance after all the rounds\r\n",
        "    acc_clients = [client.evaluate() for client in clients]\r\n",
        "\r\n",
        "    acc_s = []\r\n",
        "    for i, acc in enumerate(acc_clients):\r\n",
        "      if i not in adv_idx:\r\n",
        "        acc_s.append(acc)\r\n",
        "  \r\n",
        "    model_performance[handle][trial] = np.mean(np.array(acc_s)) # evaluation result\r\n",
        "    print(\"handle %s, trial %d\")\r\n",
        "    print(acc_s)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Data split:\n",
            " - Client 0: [96 96 96 96  0  0  0  0  0 96]\n",
            " - Client 1: [ 0  0  0  0 96 96 96 96 96  0]\n",
            " - Client 2: [96 96 96  0  0  0  0  0 96 96]\n",
            " - Client 3: [96 96  0  0  0  0  0 96 96 96]\n",
            " - Client 4: [96 96 96 96  0  0  0  0  0 96]\n",
            " - Client 5: [ 0 96 96 96 96 96  0  0  0  0]\n",
            " - Client 6: [ 0  0  0 96 96 96 96 96  0  0]\n",
            " - Client 7: [96 96 96  0  0  0  0  0 96 96]\n",
            " - Client 8: [96 96  0  0  0  0  0 96 96 96]\n",
            " - Client 9: [96  0  0  0  0  0 96 96 96 96]\n",
            " - Client 10: [ 0  0  0  0  0 96 96 96 96 96]\n",
            " - Client 11: [ 0  0  0 96 96 96 96 96  0  0]\n",
            " - Client 12: [ 0 96 96 96 96 96  0  0  0  0]\n",
            " - Client 13: [ 0  0  0  0  0 96 96 96 96 96]\n",
            " - Client 14: [ 0  0  0 96 96 96 96 96  0  0]\n",
            " - Client 15: [96 96 96  0  0  0  0  0 96 96]\n",
            " - Client 16: [ 0  0  0  0 96 96 96 96 96  0]\n",
            " - Client 17: [ 0  0 96 96 96 96 96  0  0  0]\n",
            " - Client 18: [96  0  0  0  0  0 96 96 96 96]\n",
            " - Client 19: [ 0  0  0 96 96 96 96 96  0  0]\n",
            " - Client 20: [42  0  0  0  0 71 96 79 96 96]\n",
            " - Client 21: [ 0 96 96 96 96  0 85  0 11  0]\n",
            " - Client 22: [96 96 96 96 67  0  0  0 10 19]\n",
            " - Client 23: [96 96 96 96 96  0  0  0  0  0]\n",
            " - Client 24: [ 62 212 174  15  17   0   0   0   0   0]\n",
            "\n",
            "\n",
            "Data preprocessing: \n",
            " - ToPILImage()\n",
            " - Resize(size=(28, 28), interpolation=PIL.Image.BILINEAR)\n",
            " - ToTensor()\n",
            " - Normalize(mean=(0.06078,), std=(0.1957,))\n",
            "\n",
            "0: normal\n",
            "1: normal\n",
            "2: normal\n",
            "3: normal\n",
            "4: normal\n",
            "5: normal\n",
            "6: normal\n",
            "7: normal\n",
            "8: normal\n",
            "9: normal\n",
            "10: normal\n",
            "11: normal\n",
            "12: random\n",
            "13: normal\n",
            "14: normal\n",
            "15: random\n",
            "16: random\n",
            "17: normal\n",
            "18: normal\n",
            "19: normal\n",
            "20: normal\n",
            "21: normal\n",
            "22: normal\n",
            "23: normal\n",
            "24: normal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-01dbb2be210a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparticipating_clients\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m           \u001b[0mtrain_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_weight_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m           \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/fl_devices.py\u001b[0m in \u001b[0;36mcompute_weight_update\u001b[0;34m(self, epochs, loader)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_old\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*=\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mtrain_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0msubtract_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminuend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubtrahend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_old\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/fl_devices.py\u001b[0m in \u001b[0;36mtrain_op\u001b[0;34m(self, model, loader, optimizer, epochs)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0msamples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;31m# adversary: handle gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M10ZaIvUTSN2"
      },
      "source": [
        "**Experiment 0**: Baseline without attack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8derIiLoTV1Y",
        "outputId": "f08e76ed-9604-4e77-cfd0-8b3e121731c2"
      },
      "source": [
        "# hyperparameters\r\n",
        "N_CLIENT = 25\r\n",
        "N_ADV_RANDOM = 0\r\n",
        "N_ADV_OPP = 0\r\n",
        "N_ADV_SWAP = 0\r\n",
        "\r\n",
        "# hyperparemeters\r\n",
        "TOTAL_TRIAL = 5\r\n",
        "TOTAL_ROUND = 30\r\n",
        "DETECT_ROUND = 10\r\n",
        "\r\n",
        "# ADV_HANDLE = [None, 'remove', 'reg']\r\n",
        "handle = None\r\n",
        "\r\n",
        "esp = 0.8\r\n",
        "min_samples =2\r\n",
        "reg_factor = 0.1\r\n",
        "metric = 'cosine'\r\n",
        "cfl_stats = ExperimentLogger()\r\n",
        "model_performance = defaultdict(lambda: [None] * TOTAL_TRIAL)\r\n",
        "\r\n",
        "for trial in range(TOTAL_TRIAL):\r\n",
        "  data = datasets.MNIST(root='./',download=True)\r\n",
        "  train_frac = 0.2\r\n",
        "  test_frac = 0.2 \r\n",
        "  train_num = int(train_frac * len(data))\r\n",
        "  test_num = int(test_frac * len(data))\r\n",
        "  idcs = np.random.permutation(len(data))\r\n",
        "  train_idcs, test_idcs = idcs[:train_num], idcs[train_num:train_num + test_num]\r\n",
        "  train_labels = data.train_labels.numpy()\r\n",
        "  clients_split = split_image_data(data.train_data[train_idcs], train_labels[train_idcs], n_clients=N_CLIENT, classes_per_client=5,balancedness=1)\r\n",
        "  train_trans, val_trans = get_default_data_transforms(\"EMNIST\")\r\n",
        "  client_data = [CustomImageDataset(clients_split[i][0].to(torch.float32), clients_split[i][1],transforms=train_trans ) for i in range(len(clients_split))]\r\n",
        "\r\n",
        "  test_data = data.test_data[train_num:train_num+test_num]\r\n",
        "  test_labels = train_labels[train_num:train_num+test_num]\r\n",
        "  test_data = CustomImageDataset(test_data.to(torch.float32), test_labels, transforms=val_trans)\r\n",
        "\r\n",
        "  # Assign client modes\r\n",
        "  clients = [Client(ConvNet, lambda x : torch.optim.SGD(x, lr=0.1, momentum=0.9), client_data[i], idnum=i) \r\n",
        "            for i, dat in enumerate(client_data)]\r\n",
        "  client_indx = np.random.permutation(len(clients))\r\n",
        "  offset = 0\r\n",
        "  adv_random = client_indx[0:N_ADV_RANDOM]\r\n",
        "  offset += N_ADV_RANDOM\r\n",
        "  adv_opp = client_indx[offset:offset + N_ADV_OPP]\r\n",
        "  offset += N_ADV_OPP\r\n",
        "  adv_swap = client_indx[offset:offset+N_ADV_SWAP]\r\n",
        "  offset += N_ADV_SWAP\r\n",
        "  adv_idx = np.concatenate((adv_random,adv_opp,adv_swap)).tolist()\r\n",
        "  for i in adv_random:\r\n",
        "    clients[i].client_mode = 'random'\r\n",
        "\r\n",
        "  for i in adv_opp:\r\n",
        "    clients[i].client_mode = 'opposite'\r\n",
        "\r\n",
        "  for i in adv_swap:\r\n",
        "    clients[i].client_mode = 'swap'\r\n",
        "\r\n",
        "  # print out each client and its mode\r\n",
        "  for idx, client in enumerate(clients):\r\n",
        "    print('{}: {}'.format(idx, client.client_mode))\r\n",
        "\r\n",
        "  server = Server(ConvNet, test_data)\r\n",
        "  weights = np.ones(len(clients))\r\n",
        "  for round in range(TOTAL_ROUND):\r\n",
        "    if round == 0:\r\n",
        "      for client in clients:\r\n",
        "        client.synchronize_with_server(server)\r\n",
        "    \r\n",
        "    \r\n",
        "    participating_clients = server.select_clients(clients, frac=1.0)\r\n",
        "\r\n",
        "    for client in participating_clients:\r\n",
        "        train_stats = client.compute_weight_update(epochs=1)\r\n",
        "        client.reset()\r\n",
        "      \r\n",
        "    if round + 1 == DETECT_ROUND:\r\n",
        "        # generate feature matrix for clustering\r\n",
        "        client_dW_dicts = [client.dW for client in clients]\r\n",
        "        feature_matrix = generate_feature_matrix(client_dW_dicts)\r\n",
        "\r\n",
        "        # detect adversary using clustering\r\n",
        "        clustering_label = server.detect_adversary(feature_matrix, esp, min_samples, metric)\r\n",
        "        adv_idx_label = np.argwhere(clustering_label == -1).flatten()\r\n",
        "\r\n",
        "        # update clients by handling adversary detected\r\n",
        "        weights = handle_adversary(adv_idx_label, handle, weights,reg_factor)\r\n",
        "\r\n",
        "    # aggregate weight updates; copy new weights to clients\r\n",
        "    server.aggregate_wieght_updates_weight(clients, weights)\r\n",
        "    server.copy_weights(clients)\r\n",
        "              \r\n",
        "  # evaluate model performance after all the rounds\r\n",
        "  acc_clients = [client.evaluate() for client in clients]\r\n",
        "\r\n",
        "  acc_s = []\r\n",
        "  for i, acc in enumerate(acc_clients):\r\n",
        "    if i not in adv_idx:\r\n",
        "      acc_s.append(acc)\r\n",
        "\r\n",
        "  model_performance[handle][trial] = np.mean(np.array(acc_s)) # evaluation result\r\n",
        "  print(\"handle %s, trial %d\")\r\n",
        "  print(acc_s)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Data split:\n",
            " - Client 0: [96  0  0  0  0  0 96 96 96 96]\n",
            " - Client 1: [ 0  0 96 96 96 96 96  0  0  0]\n",
            " - Client 2: [ 0  0  0  0 96 96 96 96 96  0]\n",
            " - Client 3: [96 96 96  0  0  0  0  0 96 96]\n",
            " - Client 4: [96 96 96 96 96  0  0  0  0  0]\n",
            " - Client 5: [96 96 96 96  0  0  0  0  0 96]\n",
            " - Client 6: [96 96 96  0  0  0  0  0 96 96]\n",
            " - Client 7: [ 0  0 96 96 96 96 96  0  0  0]\n",
            " - Client 8: [96 96  0  0  0  0  0 96 96 96]\n",
            " - Client 9: [96 96 96 96 96  0  0  0  0  0]\n",
            " - Client 10: [96 96 96 96 96  0  0  0  0  0]\n",
            " - Client 11: [ 0  0  0 96 96 96 96 96  0  0]\n",
            " - Client 12: [ 0  0  0  0  0 96 96 96 96 96]\n",
            " - Client 13: [96  0  0  0  0  0 96 96 96 96]\n",
            " - Client 14: [96  0  0  0  0  0 96 96 96 96]\n",
            " - Client 15: [ 0  0 96 96 96 96 96  0  0  0]\n",
            " - Client 16: [ 0  0  0 96 96 96 96 96  0  0]\n",
            " - Client 17: [ 0  0 96 96 96 96 96  0  0  0]\n",
            " - Client 18: [ 0  0 96 96 96 96 96  0  0  0]\n",
            " - Client 19: [ 0  0 84 96 80 96 71 53  0  0]\n",
            " - Client 20: [96 96  0  0  0  0  0 96 96 96]\n",
            " - Client 21: [96 96  0 96  0 96  0  0  0 96]\n",
            " - Client 22: [66 96  0 11  0 19  0 96 96 96]\n",
            " - Client 23: [  0  96   0   0   0  14   0 178  96  96]\n",
            " - Client 24: [  0 313   0   0   0   0   0  35 106  26]\n",
            "\n",
            "\n",
            "Data preprocessing: \n",
            " - ToPILImage()\n",
            " - Resize(size=(28, 28), interpolation=PIL.Image.BILINEAR)\n",
            " - ToTensor()\n",
            " - Normalize(mean=(0.06078,), std=(0.1957,))\n",
            "\n",
            "0: normal\n",
            "1: normal\n",
            "2: normal\n",
            "3: normal\n",
            "4: normal\n",
            "5: normal\n",
            "6: normal\n",
            "7: normal\n",
            "8: normal\n",
            "9: normal\n",
            "10: normal\n",
            "11: normal\n",
            "12: normal\n",
            "13: normal\n",
            "14: normal\n",
            "15: normal\n",
            "16: normal\n",
            "17: normal\n",
            "18: normal\n",
            "19: normal\n",
            "20: normal\n",
            "21: normal\n",
            "22: normal\n",
            "23: normal\n",
            "24: normal\n",
            "handle %s, trial %d\n",
            "[0.8541666666666666, 0.84375, 0.8229166666666666, 0.84375, 0.875, 0.90625, 0.875, 0.8333333333333334, 0.84375, 0.8541666666666666, 0.84375, 0.7604166666666666, 0.8645833333333334, 0.8854166666666666, 0.8854166666666666, 0.7604166666666666, 0.8229166666666666, 0.7395833333333334, 0.875, 0.8125, 0.875, 0.7916666666666666, 0.8333333333333334, 0.8854166666666666, 0.90625]\n",
            "Data split:\n",
            " - Client 0: [ 0  0  0  0 96 96 96 96 96  0]\n",
            " - Client 1: [ 0  0 96 96 96 96 96  0  0  0]\n",
            " - Client 2: [ 0  0  0 96 96 96 96 96  0  0]\n",
            " - Client 3: [ 0  0 96 96 96 96 96  0  0  0]\n",
            " - Client 4: [96 96 96  0  0  0  0  0 96 96]\n",
            " - Client 5: [96 96 96 96  0  0  0  0  0 96]\n",
            " - Client 6: [ 0  0 96 96 96 96 96  0  0  0]\n",
            " - Client 7: [96  0  0  0  0  0 96 96 96 96]\n",
            " - Client 8: [96 96 96 96  0  0  0  0  0 96]\n",
            " - Client 9: [96 96 96 96  0  0  0  0  0 96]\n",
            " - Client 10: [ 0 96 96 96 96 96  0  0  0  0]\n",
            " - Client 11: [96  0  0  0  0  0 96 96 96 96]\n",
            " - Client 12: [96 96 96 96  0  0  0  0  0 96]\n",
            " - Client 13: [ 0  0 96 96 96 96 96  0  0  0]\n",
            " - Client 14: [ 0  0  0  0  0 96 96 96 96 96]\n",
            " - Client 15: [ 0  0  0 96 96 96 96 96  0  0]\n",
            " - Client 16: [96  0  0  0  0  0 96 96 96 96]\n",
            " - Client 17: [96 96  0  0  0  0  0 96 96 96]\n",
            " - Client 18: [ 0  0  0  0  0 96 96 96 96 96]\n",
            " - Client 19: [ 0  0  0 96 96 96 62 96 34  0]\n",
            " - Client 20: [96 96 96 57 39  0  0  0  0 96]\n",
            " - Client 21: [96 96 51  0  0  0  0 96 96 45]\n",
            " - Client 22: [96 22 32  0 96 42  0 96 96  0]\n",
            " - Client 23: [ 15 177   0   0  96   0   0  96  96   0]\n",
            " - Client 24: [  0 338   0   0  72   0   0  16  54   0]\n",
            "\n",
            "\n",
            "Data preprocessing: \n",
            " - ToPILImage()\n",
            " - Resize(size=(28, 28), interpolation=PIL.Image.BILINEAR)\n",
            " - ToTensor()\n",
            " - Normalize(mean=(0.06078,), std=(0.1957,))\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0: normal\n",
            "1: normal\n",
            "2: normal\n",
            "3: normal\n",
            "4: normal\n",
            "5: normal\n",
            "6: normal\n",
            "7: normal\n",
            "8: normal\n",
            "9: normal\n",
            "10: normal\n",
            "11: normal\n",
            "12: normal\n",
            "13: normal\n",
            "14: normal\n",
            "15: normal\n",
            "16: normal\n",
            "17: normal\n",
            "18: normal\n",
            "19: normal\n",
            "20: normal\n",
            "21: normal\n",
            "22: normal\n",
            "23: normal\n",
            "24: normal\n",
            "handle %s, trial %d\n",
            "[0.7291666666666666, 0.7604166666666666, 0.8958333333333334, 0.8020833333333334, 0.8020833333333334, 0.8229166666666666, 0.7708333333333334, 0.84375, 0.8229166666666666, 0.8333333333333334, 0.6979166666666666, 0.8020833333333334, 0.7708333333333334, 0.7395833333333334, 0.8020833333333334, 0.78125, 0.7291666666666666, 0.8229166666666666, 0.8125, 0.78125, 0.8229166666666666, 0.8645833333333334, 0.8020833333333334, 0.8541666666666666, 0.9166666666666666]\n",
            "Data split:\n",
            " - Client 0: [ 0  0  0 96 96 96 96 96  0  0]\n",
            " - Client 1: [96 96 96  0  0  0  0  0 96 96]\n",
            " - Client 2: [96 96 96 96 96  0  0  0  0  0]\n",
            " - Client 3: [ 0  0  0  0  0 96 96 96 96 96]\n",
            " - Client 4: [ 0  0  0 96 96 96 96 96  0  0]\n",
            " - Client 5: [96  0  0  0  0  0 96 96 96 96]\n",
            " - Client 6: [ 0  0  0  0 96 96 96 96 96  0]\n",
            " - Client 7: [ 0  0 96 96 96 96 96  0  0  0]\n",
            " - Client 8: [ 0  0  0 96 96 96 96 96  0  0]\n",
            " - Client 9: [ 0  0  0  0  0 96 96 96 96 96]\n",
            " - Client 10: [ 0  0  0 96 96 96 96 96  0  0]\n",
            " - Client 11: [ 0  0  0  0  0 96 96 96 96 96]\n",
            " - Client 12: [ 0  0  0 96 96 96 96 96  0  0]\n",
            " - Client 13: [96 96 96  0  0  0  0  0 96 96]\n",
            " - Client 14: [ 0  0  0  0 96 96 96 96 96  0]\n",
            " - Client 15: [96 96 96  0  0  0  0  0 96 96]\n",
            " - Client 16: [96 43  0  0  0 50  3 96 96 96]\n",
            " - Client 17: [ 0 96 96 96 96  0  0 96  0  0]\n",
            " - Client 18: [ 0  0 96 96 96  0  0  2 96 94]\n",
            " - Client 19: [96 96 96 25  0  0  0  0 71 96]\n",
            " - Client 20: [96 96 96 96 96  0  0  0  0  0]\n",
            " - Client 21: [96 96 96 96  0  0  0  0  0 96]\n",
            " - Client 22: [96 96 96 96  0  0  0  0  0 96]\n",
            " - Client 23: [180  96  96  62  20   0   0   0   0  26]\n",
            " - Client 24: [ 88 347  45   0   0   0   0   0   0   0]\n",
            "\n",
            "\n",
            "Data preprocessing: \n",
            " - ToPILImage()\n",
            " - Resize(size=(28, 28), interpolation=PIL.Image.BILINEAR)\n",
            " - ToTensor()\n",
            " - Normalize(mean=(0.06078,), std=(0.1957,))\n",
            "\n",
            "0: normal\n",
            "1: normal\n",
            "2: normal\n",
            "3: normal\n",
            "4: normal\n",
            "5: normal\n",
            "6: normal\n",
            "7: normal\n",
            "8: normal\n",
            "9: normal\n",
            "10: normal\n",
            "11: normal\n",
            "12: normal\n",
            "13: normal\n",
            "14: normal\n",
            "15: normal\n",
            "16: normal\n",
            "17: normal\n",
            "18: normal\n",
            "19: normal\n",
            "20: normal\n",
            "21: normal\n",
            "22: normal\n",
            "23: normal\n",
            "24: normal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "handle %s, trial %d\n",
            "[0.7916666666666666, 0.8229166666666666, 0.8541666666666666, 0.875, 0.7604166666666666, 0.8125, 0.8125, 0.8333333333333334, 0.8229166666666666, 0.7291666666666666, 0.78125, 0.8541666666666666, 0.84375, 0.8541666666666666, 0.78125, 0.8854166666666666, 0.78125, 0.8958333333333334, 0.8020833333333334, 0.8645833333333334, 0.8333333333333334, 0.7916666666666666, 0.78125, 0.8541666666666666, 0.9270833333333334]\n",
            "Data split:\n",
            " - Client 0: [ 0  0  0 96 96 96 96 96  0  0]\n",
            " - Client 1: [ 0  0 96 96 96 96 96  0  0  0]\n",
            " - Client 2: [96 96 96 96  0  0  0  0  0 96]\n",
            " - Client 3: [96 96 96 96 96  0  0  0  0  0]\n",
            " - Client 4: [ 0 96 96 96 96 96  0  0  0  0]\n",
            " - Client 5: [96 96  0  0  0  0  0 96 96 96]\n",
            " - Client 6: [ 0  0  0  0  0 96 96 96 96 96]\n",
            " - Client 7: [96 96 96  0  0  0  0  0 96 96]\n",
            " - Client 8: [96 96 96  0  0  0  0  0 96 96]\n",
            " - Client 9: [96 96 96 96 96  0  0  0  0  0]\n",
            " - Client 10: [96 96 96  0  0  0  0  0 96 96]\n",
            " - Client 11: [ 0  0  0  0  0 96 96 96 96 96]\n",
            " - Client 12: [ 0 96 96 96 96 96  0  0  0  0]\n",
            " - Client 13: [96  0  0  0  0  0 96 96 96 96]\n",
            " - Client 14: [96 96 96 96 96  0  0  0  0  0]\n",
            " - Client 15: [96 96  0  0  0  0  0 96 96 96]\n",
            " - Client 16: [ 0  0 96 96 96 96 96  0  0  0]\n",
            " - Client 17: [96  0  0  0  0  0 96 96 96 96]\n",
            " - Client 18: [ 0  0  0  0  0 96 96 96 96 96]\n",
            " - Client 19: [ 0  0  0  0 96 96 96 96 96  0]\n",
            " - Client 20: [ 0  0  0  0  0 96 96 96 96 96]\n",
            " - Client 21: [96 96 96 46  0  0  0 96  0 50]\n",
            " - Client 22: [53 96 43  0  0 96 96 96  0  0]\n",
            " - Client 23: [ 0 48  0 96 96 48 96 96  0  0]\n",
            " - Client 24: [  0  66  25 184 177   0  12  16   0   0]\n",
            "\n",
            "\n",
            "Data preprocessing: \n",
            " - ToPILImage()\n",
            " - Resize(size=(28, 28), interpolation=PIL.Image.BILINEAR)\n",
            " - ToTensor()\n",
            " - Normalize(mean=(0.06078,), std=(0.1957,))\n",
            "\n",
            "0: normal\n",
            "1: normal\n",
            "2: normal\n",
            "3: normal\n",
            "4: normal\n",
            "5: normal\n",
            "6: normal\n",
            "7: normal\n",
            "8: normal\n",
            "9: normal\n",
            "10: normal\n",
            "11: normal\n",
            "12: normal\n",
            "13: normal\n",
            "14: normal\n",
            "15: normal\n",
            "16: normal\n",
            "17: normal\n",
            "18: normal\n",
            "19: normal\n",
            "20: normal\n",
            "21: normal\n",
            "22: normal\n",
            "23: normal\n",
            "24: normal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "handle %s, trial %d\n",
            "[0.78125, 0.8645833333333334, 0.8125, 0.875, 0.875, 0.84375, 0.8854166666666666, 0.8645833333333334, 0.84375, 0.8541666666666666, 0.8854166666666666, 0.8333333333333334, 0.8020833333333334, 0.8229166666666666, 0.84375, 0.8958333333333334, 0.8020833333333334, 0.8229166666666666, 0.8125, 0.7604166666666666, 0.8020833333333334, 0.8958333333333334, 0.8541666666666666, 0.78125, 0.8333333333333334]\n",
            "Data split:\n",
            " - Client 0: [96 96 96 96 96  0  0  0  0  0]\n",
            " - Client 1: [96 96 96  0  0  0  0  0 96 96]\n",
            " - Client 2: [96 96 96 96  0  0  0  0  0 96]\n",
            " - Client 3: [ 0  0  0 96 96 96 96 96  0  0]\n",
            " - Client 4: [ 0  0  0  0  0 96 96 96 96 96]\n",
            " - Client 5: [ 0  0  0  0  0 96 96 96 96 96]\n",
            " - Client 6: [96 96 96  0  0  0  0  0 96 96]\n",
            " - Client 7: [96 96  0  0  0  0  0 96 96 96]\n",
            " - Client 8: [96  0  0  0  0  0 96 96 96 96]\n",
            " - Client 9: [96 96 96 96 96  0  0  0  0  0]\n",
            " - Client 10: [96 96 96  0  0  0  0  0 96 96]\n",
            " - Client 11: [ 0  0  0  0 96 96 96 96 96  0]\n",
            " - Client 12: [ 0  0  0 96 96 96 96 96  0  0]\n",
            " - Client 13: [96 96  0  0  0  0  0 96 96 96]\n",
            " - Client 14: [ 0  0  0 96 96 96 96 96  0  0]\n",
            " - Client 15: [ 0  0  0 96 96 96 96 96  0  0]\n",
            " - Client 16: [ 0  0  0  0 96 96 96 96 96  0]\n",
            " - Client 17: [ 0  0 96 96 96 96 96  0  0  0]\n",
            " - Client 18: [96 96 96 96 96  0  0  0  0  0]\n",
            " - Client 19: [ 0  0  0 96 96 96 96 96  0  0]\n",
            " - Client 20: [ 0  0 96 96 96 96 76 20  0  0]\n",
            " - Client 21: [59  0  0 96 27 41  0 65 96 96]\n",
            " - Client 22: [40 96 96 56  0  0  0  0 96 96]\n",
            " - Client 23: [106 139  96   0   0   0   0   0  21 118]\n",
            " - Client 24: [  0 323 157   0   0   0   0   0   0   0]\n",
            "\n",
            "\n",
            "Data preprocessing: \n",
            " - ToPILImage()\n",
            " - Resize(size=(28, 28), interpolation=PIL.Image.BILINEAR)\n",
            " - ToTensor()\n",
            " - Normalize(mean=(0.06078,), std=(0.1957,))\n",
            "\n",
            "0: normal\n",
            "1: normal\n",
            "2: normal\n",
            "3: normal\n",
            "4: normal\n",
            "5: normal\n",
            "6: normal\n",
            "7: normal\n",
            "8: normal\n",
            "9: normal\n",
            "10: normal\n",
            "11: normal\n",
            "12: normal\n",
            "13: normal\n",
            "14: normal\n",
            "15: normal\n",
            "16: normal\n",
            "17: normal\n",
            "18: normal\n",
            "19: normal\n",
            "20: normal\n",
            "21: normal\n",
            "22: normal\n",
            "23: normal\n",
            "24: normal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "handle %s, trial %d\n",
            "[0.75, 0.8229166666666666, 0.8125, 0.78125, 0.8020833333333334, 0.8333333333333334, 0.8229166666666666, 0.8333333333333334, 0.875, 0.8645833333333334, 0.8854166666666666, 0.8333333333333334, 0.7916666666666666, 0.84375, 0.875, 0.78125, 0.8229166666666666, 0.7708333333333334, 0.8229166666666666, 0.8333333333333334, 0.8229166666666666, 0.7291666666666666, 0.78125, 0.90625, 0.9479166666666666]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3BDfeTSdGS1"
      },
      "source": [
        "**Experiment 1.1**: Random Attack, None detect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL7DY_R3dTJ0",
        "outputId": "f1b9b927-9451-43e0-a9c2-78f89a476c3b"
      },
      "source": [
        "# hyperparameters\r\n",
        "N_CLIENT = 25\r\n",
        "N_ADV_RANDOM = 3\r\n",
        "N_ADV_OPP = 0\r\n",
        "N_ADV_SWAP = 0\r\n",
        "\r\n",
        "# hyperparemeters\r\n",
        "TOTAL_TRIAL = 5\r\n",
        "TOTAL_ROUND = 30\r\n",
        "DETECT_ROUND = 10\r\n",
        "\r\n",
        "# ADV_HANDLE = [None, 'remove', 'reg']\r\n",
        "handle = None\r\n",
        "\r\n",
        "esp = 0.8\r\n",
        "min_samples =2\r\n",
        "reg_factor = 0.1\r\n",
        "metric = 'cosine'\r\n",
        "cfl_stats = ExperimentLogger()\r\n",
        "model_performance = defaultdict(lambda: [None] * TOTAL_TRIAL)\r\n",
        "\r\n",
        "for trial in range(TOTAL_TRIAL):\r\n",
        "  data = datasets.MNIST(root='./',download=True)\r\n",
        "  train_frac = 0.5\r\n",
        "  test_frac = 0.2 \r\n",
        "  train_num = int(train_frac * len(data))\r\n",
        "  test_num = int(test_frac * len(data))\r\n",
        "  idcs = np.random.permutation(len(data))\r\n",
        "  train_idcs, test_idcs = idcs[:train_num], idcs[train_num:train_num + test_num]\r\n",
        "  train_labels = data.train_labels.numpy()\r\n",
        "  clients_split = split_image_data(data.train_data[train_idcs], train_labels[train_idcs], n_clients=N_CLIENT, classes_per_client=5,balancedness=1)\r\n",
        "  train_trans, val_trans = get_default_data_transforms(\"EMNIST\")\r\n",
        "  client_data = [CustomImageDataset(clients_split[i][0].to(torch.float32), clients_split[i][1],transforms=train_trans ) for i in range(len(clients_split))]\r\n",
        "\r\n",
        "  test_data = data.test_data[train_num:train_num+test_num]\r\n",
        "  test_labels = train_labels[train_num:train_num+test_num]\r\n",
        "  test_data = CustomImageDataset(test_data.to(torch.float32), test_labels, transforms=val_trans)\r\n",
        "\r\n",
        "  # Assign client modes\r\n",
        "  clients = [Client(ConvNet, lambda x : torch.optim.SGD(x, lr=0.1, momentum=0.9), client_data[i], idnum=i) \r\n",
        "            for i, dat in enumerate(client_data)]\r\n",
        "  client_indx = np.random.permutation(len(clients))\r\n",
        "  offset = 0\r\n",
        "  adv_random = client_indx[0:N_ADV_RANDOM]\r\n",
        "  offset += N_ADV_RANDOM\r\n",
        "  adv_opp = client_indx[offset:offset + N_ADV_OPP]\r\n",
        "  offset += N_ADV_OPP\r\n",
        "  adv_swap = client_indx[offset:offset+N_ADV_SWAP]\r\n",
        "  offset += N_ADV_SWAP\r\n",
        "  adv_idx = np.concatenate((adv_random,adv_opp,adv_swap)).tolist()\r\n",
        "  for i in adv_random:\r\n",
        "    clients[i].client_mode = 'random'\r\n",
        "\r\n",
        "  for i in adv_opp:\r\n",
        "    clients[i].client_mode = 'opposite'\r\n",
        "\r\n",
        "  for i in adv_swap:\r\n",
        "    clients[i].client_mode = 'swap'\r\n",
        "\r\n",
        "  # print out each client and its mode\r\n",
        "  for idx, client in enumerate(clients):\r\n",
        "    print('{}: {}'.format(idx, client.client_mode))\r\n",
        "\r\n",
        "  server = Server(ConvNet, test_data)\r\n",
        "  weights = np.ones(len(clients))\r\n",
        "  for round in range(TOTAL_ROUND):\r\n",
        "    if round == 0:\r\n",
        "      for client in clients:\r\n",
        "        client.synchronize_with_server(server)\r\n",
        "    \r\n",
        "    \r\n",
        "    participating_clients = server.select_clients(clients, frac=1.0)\r\n",
        "\r\n",
        "    for client in participating_clients:\r\n",
        "        train_stats = client.compute_weight_update(epochs=1)\r\n",
        "        client.reset()\r\n",
        "      \r\n",
        "    if round + 1 == DETECT_ROUND:\r\n",
        "        # generate feature matrix for clustering\r\n",
        "        client_dW_dicts = [client.dW for client in clients]\r\n",
        "        feature_matrix = generate_feature_matrix(client_dW_dicts)\r\n",
        "\r\n",
        "        # detect adversary using clustering\r\n",
        "        clustering_label = server.detect_adversary(feature_matrix, esp, min_samples, metric)\r\n",
        "        adv_idx_label = np.argwhere(clustering_label == -1).flatten()\r\n",
        "\r\n",
        "        # update clients by handling adversary detected\r\n",
        "        weights = handle_adversary(adv_idx_label, handle, weights,reg_factor)\r\n",
        "\r\n",
        "    # aggregate weight updates; copy new weights to clients\r\n",
        "    server.aggregate_wieght_updates_weight(clients, weights)\r\n",
        "    server.copy_weights(clients)\r\n",
        "              \r\n",
        "  # evaluate model performance after all the rounds\r\n",
        "  acc_clients = [client.evaluate() for client in clients]\r\n",
        "\r\n",
        "  acc_s = []\r\n",
        "  for i, acc in enumerate(acc_clients):\r\n",
        "    if i not in adv_idx:\r\n",
        "      acc_s.append(acc)\r\n",
        "\r\n",
        "  model_performance[handle][trial] = np.mean(np.array(acc_s)) # evaluation result\r\n",
        "  print(\"handle %s, trial %d\"%(handle, trial))\r\n",
        "  print(acc_s)\r\n",
        "print(\"average performance %f\"%(np.mean(model_performance[handle])))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Data split:\n",
            " - Client 0: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 1: [  0   0 240 240 240 240 240   0   0   0]\n",
            " - Client 2: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 3: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 4: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 5: [  0   0 240 240 240 240 240   0   0   0]\n",
            " - Client 6: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 7: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 8: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 9: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 10: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 11: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 12: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 13: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 14: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 15: [240 240   0   0   0   0   0 240 240 240]\n",
            " - Client 16: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 17: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 18: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 19: [  0 240  89 240 240 240 151   0   0   0]\n",
            " - Client 20: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 21: [  0 240   0 153  24 240 240 240  63   0]\n",
            " - Client 22: [  0 212   0   0   0 240 240 240 240  28]\n",
            " - Client 23: [114   0   0   0   0  65 213 240 328 240]\n",
            " - Client 24: [  0   0   0   0   0   0   0 497 138 565]\n",
            "\n",
            "\n",
            "Data preprocessing: \n",
            " - ToPILImage()\n",
            " - Resize(size=(28, 28), interpolation=PIL.Image.BILINEAR)\n",
            " - ToTensor()\n",
            " - Normalize(mean=(0.06078,), std=(0.1957,))\n",
            "\n",
            "0: normal\n",
            "1: normal\n",
            "2: random\n",
            "3: normal\n",
            "4: random\n",
            "5: normal\n",
            "6: normal\n",
            "7: normal\n",
            "8: normal\n",
            "9: normal\n",
            "10: normal\n",
            "11: normal\n",
            "12: normal\n",
            "13: normal\n",
            "14: normal\n",
            "15: normal\n",
            "16: normal\n",
            "17: normal\n",
            "18: normal\n",
            "19: normal\n",
            "20: normal\n",
            "21: normal\n",
            "22: random\n",
            "23: normal\n",
            "24: normal\n",
            "handle None, trial 0\n",
            "[0.3458333333333333, 0.32083333333333336, 0.4666666666666667, 0.38333333333333336, 0.44166666666666665, 0.48333333333333334, 0.49583333333333335, 0.425, 0.44583333333333336, 0.3416666666666667, 0.5041666666666667, 0.35, 0.45416666666666666, 0.45, 0.5458333333333333, 0.37083333333333335, 0.44166666666666665, 0.49583333333333335, 0.36666666666666664, 0.5333333333333333, 0.35, 0.375]\n",
            "Data split:\n",
            " - Client 0: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 1: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 2: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 3: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 4: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 5: [  0   0 240 240 240 240 240   0   0   0]\n",
            " - Client 6: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 7: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 8: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 9: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 10: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 11: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 12: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 13: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 14: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 15: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 16: [240 240   0   0   0   0   0 240 240 240]\n",
            " - Client 17: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 18: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 19: [240 240 240 240 100   0   0   0   0 140]\n",
            " - Client 20: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 21: [ 86 240 154   0   0   0 240 240 240   0]\n",
            " - Client 22: [  0 240 240 240  17   0   0 223 240   0]\n",
            " - Client 23: [  0 251 172 148 240 240  81   0  68   0]\n",
            " - Client 24: [  0 268   0   0 609 323   0   0   0   0]\n",
            "\n",
            "\n",
            "Data preprocessing: \n",
            " - ToPILImage()\n",
            " - Resize(size=(28, 28), interpolation=PIL.Image.BILINEAR)\n",
            " - ToTensor()\n",
            " - Normalize(mean=(0.06078,), std=(0.1957,))\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0: normal\n",
            "1: normal\n",
            "2: normal\n",
            "3: normal\n",
            "4: normal\n",
            "5: normal\n",
            "6: normal\n",
            "7: random\n",
            "8: normal\n",
            "9: normal\n",
            "10: normal\n",
            "11: random\n",
            "12: normal\n",
            "13: normal\n",
            "14: normal\n",
            "15: normal\n",
            "16: normal\n",
            "17: normal\n",
            "18: normal\n",
            "19: normal\n",
            "20: normal\n",
            "21: normal\n",
            "22: normal\n",
            "23: random\n",
            "24: normal\n",
            "handle None, trial 1\n",
            "[0.8291666666666667, 0.8458333333333333, 0.8083333333333333, 0.8291666666666667, 0.8458333333333333, 0.7708333333333334, 0.775, 0.7541666666666667, 0.7416666666666667, 0.8375, 0.775, 0.7625, 0.7625, 0.8333333333333334, 0.8708333333333333, 0.7958333333333333, 0.775, 0.7833333333333333, 0.7125, 0.8416666666666667, 0.8125, 0.7916666666666666]\n",
            "Data split:\n",
            " - Client 0: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 1: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 2: [240 240   0   0   0   0   0 240 240 240]\n",
            " - Client 3: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 4: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 5: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 6: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 7: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 8: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 9: [  0   0 240 240 240 240 240   0   0   0]\n",
            " - Client 10: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 11: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 12: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 13: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 14: [  0   0 240 240 240 240 240   0   0   0]\n",
            " - Client 15: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 16: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 17: [  0   0   0 240 240 240  92 240 148   0]\n",
            " - Client 18: [240 240   0   0   0   0   0 240 240 240]\n",
            " - Client 19: [  0 240 240 240 240  32   0  22 121  65]\n",
            " - Client 20: [240   0 240 240 240   0   0   0   0 240]\n",
            " - Client 21: [240 240 240 240  36   0   0   0   0 204]\n",
            " - Client 22: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 23: [294 302 240 230   0   0   0   0   0 134]\n",
            " - Client 24: [  0 864 336   0   0   0   0   0   0   0]\n",
            "\n",
            "\n",
            "Data preprocessing: \n",
            " - ToPILImage()\n",
            " - Resize(size=(28, 28), interpolation=PIL.Image.BILINEAR)\n",
            " - ToTensor()\n",
            " - Normalize(mean=(0.06078,), std=(0.1957,))\n",
            "\n",
            "0: normal\n",
            "1: normal\n",
            "2: normal\n",
            "3: normal\n",
            "4: normal\n",
            "5: random\n",
            "6: normal\n",
            "7: normal\n",
            "8: random\n",
            "9: normal\n",
            "10: normal\n",
            "11: normal\n",
            "12: random\n",
            "13: normal\n",
            "14: normal\n",
            "15: normal\n",
            "16: normal\n",
            "17: normal\n",
            "18: normal\n",
            "19: normal\n",
            "20: normal\n",
            "21: normal\n",
            "22: normal\n",
            "23: normal\n",
            "24: normal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "handle None, trial 2\n",
            "[0.6291666666666667, 0.7708333333333334, 0.8583333333333333, 0.7041666666666667, 0.6333333333333333, 0.8416666666666667, 0.7333333333333333, 0.6791666666666667, 0.8166666666666667, 0.8333333333333334, 0.8166666666666667, 0.65, 0.6666666666666666, 0.8041666666666667, 0.6375, 0.8416666666666667, 0.7541666666666667, 0.6875, 0.775, 0.825, 0.8208333333333333, 0.9041666666666667]\n",
            "Data split:\n",
            " - Client 0: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 1: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 2: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 3: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 4: [240 240   0   0   0   0   0 240 240 240]\n",
            " - Client 5: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 6: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 7: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 8: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 9: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 10: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 11: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 12: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 13: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 14: [240 240   0   0   0   0   0 240 240 240]\n",
            " - Client 15: [  0   0 240 240 240 240 240   0   0   0]\n",
            " - Client 16: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 17: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 18: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 19: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 20: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 21: [  0   0   0 240 240 112 240 240  70  58]\n",
            " - Client 22: [240 240   0   0   0   0 240 240   0 240]\n",
            " - Client 23: [240 201 240 240  60   0 219   0   0   0]\n",
            " - Client 24: [ 56   0  53 392   0   0 113 241   0 345]\n",
            "\n",
            "\n",
            "Data preprocessing: \n",
            " - ToPILImage()\n",
            " - Resize(size=(28, 28), interpolation=PIL.Image.BILINEAR)\n",
            " - ToTensor()\n",
            " - Normalize(mean=(0.06078,), std=(0.1957,))\n",
            "\n",
            "0: normal\n",
            "1: normal\n",
            "2: normal\n",
            "3: normal\n",
            "4: normal\n",
            "5: normal\n",
            "6: normal\n",
            "7: normal\n",
            "8: normal\n",
            "9: normal\n",
            "10: normal\n",
            "11: normal\n",
            "12: normal\n",
            "13: normal\n",
            "14: normal\n",
            "15: normal\n",
            "16: normal\n",
            "17: normal\n",
            "18: random\n",
            "19: normal\n",
            "20: random\n",
            "21: normal\n",
            "22: normal\n",
            "23: random\n",
            "24: normal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "handle None, trial 3\n",
            "[0.7583333333333333, 0.8041666666666667, 0.775, 0.6583333333333333, 0.8166666666666667, 0.8375, 0.7375, 0.85, 0.8458333333333333, 0.6791666666666667, 0.7208333333333333, 0.6375, 0.6708333333333333, 0.7125, 0.8583333333333333, 0.6791666666666667, 0.8583333333333333, 0.6958333333333333, 0.8291666666666667, 0.6666666666666666, 0.8708333333333333, 0.7125]\n",
            "Data split:\n",
            " - Client 0: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 1: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 2: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 3: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 4: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 5: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 6: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 7: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 8: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 9: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 10: [  0   0 240 240 240 240 240   0   0   0]\n",
            " - Client 11: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 12: [  0   0 240 240 240 240 240   0   0   0]\n",
            " - Client 13: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 14: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 15: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 16: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 17: [153   0   0   0   0  87 240 240 240 240]\n",
            " - Client 18: [240 240 240 144  96   0   0   0   0 240]\n",
            " - Client 19: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 20: [ 67   0   0   0 173   0 240 240 240 240]\n",
            " - Client 21: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 22: [ 20 240 126   0   0   0  94 240 240 240]\n",
            " - Client 23: [240 240   0   0   0   0   0 240 355 125]\n",
            " - Client 24: [342 447   0   0   0   0   0 257 154   0]\n",
            "\n",
            "\n",
            "Data preprocessing: \n",
            " - ToPILImage()\n",
            " - Resize(size=(28, 28), interpolation=PIL.Image.BILINEAR)\n",
            " - ToTensor()\n",
            " - Normalize(mean=(0.06078,), std=(0.1957,))\n",
            "\n",
            "0: normal\n",
            "1: normal\n",
            "2: normal\n",
            "3: random\n",
            "4: normal\n",
            "5: normal\n",
            "6: random\n",
            "7: normal\n",
            "8: normal\n",
            "9: normal\n",
            "10: normal\n",
            "11: normal\n",
            "12: normal\n",
            "13: normal\n",
            "14: normal\n",
            "15: normal\n",
            "16: normal\n",
            "17: normal\n",
            "18: normal\n",
            "19: random\n",
            "20: normal\n",
            "21: normal\n",
            "22: normal\n",
            "23: normal\n",
            "24: normal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "handle None, trial 4\n",
            "[0.7625, 0.7291666666666666, 0.7791666666666667, 0.8125, 0.7708333333333334, 0.7916666666666666, 0.7333333333333333, 0.7833333333333333, 0.7125, 0.825, 0.7583333333333333, 0.6875, 0.7166666666666667, 0.8333333333333334, 0.8041666666666667, 0.7916666666666666, 0.8458333333333333, 0.7416666666666667, 0.7916666666666666, 0.8041666666666667, 0.7833333333333333, 0.8833333333333333]\n",
            "average performance 0.704015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40jzAIl5j7AY"
      },
      "source": [
        "**Experiment 1.2**: Flip Attack, None detect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNukkdockBU4",
        "outputId": "bef7684a-72b2-4bbf-95b3-34ffaea68ed6"
      },
      "source": [
        "# hyperparameters\r\n",
        "N_CLIENT = 25\r\n",
        "N_ADV_RANDOM = 0\r\n",
        "N_ADV_OPP = 0\r\n",
        "N_ADV_SWAP = 3\r\n",
        "\r\n",
        "# hyperparemeters\r\n",
        "TOTAL_TRIAL = 5\r\n",
        "TOTAL_ROUND = 30\r\n",
        "DETECT_ROUND = 10\r\n",
        "\r\n",
        "# ADV_HANDLE = [None, 'remove', 'reg']\r\n",
        "handle = None\r\n",
        "\r\n",
        "esp = 0.8\r\n",
        "min_samples =2\r\n",
        "reg_factor = 0.1\r\n",
        "metric = 'cosine'\r\n",
        "cfl_stats = ExperimentLogger()\r\n",
        "model_performance = defaultdict(lambda: [None] * TOTAL_TRIAL)\r\n",
        "\r\n",
        "for trial in range(TOTAL_TRIAL):\r\n",
        "  data = datasets.MNIST(root='./',download=True)\r\n",
        "  train_frac = 0.5\r\n",
        "  test_frac = 0.2 \r\n",
        "  train_num = int(train_frac * len(data))\r\n",
        "  test_num = int(test_frac * len(data))\r\n",
        "  idcs = np.random.permutation(len(data))\r\n",
        "  train_idcs, test_idcs = idcs[:train_num], idcs[train_num:train_num + test_num]\r\n",
        "  train_labels = data.train_labels.numpy()\r\n",
        "  clients_split = split_image_data(data.train_data[train_idcs], train_labels[train_idcs], n_clients=N_CLIENT, classes_per_client=5,balancedness=1)\r\n",
        "  train_trans, val_trans = get_default_data_transforms(\"EMNIST\")\r\n",
        "  client_data = [CustomImageDataset(clients_split[i][0].to(torch.float32), clients_split[i][1],transforms=train_trans ) for i in range(len(clients_split))]\r\n",
        "\r\n",
        "  test_data = data.test_data[train_num:train_num+test_num]\r\n",
        "  test_labels = train_labels[train_num:train_num+test_num]\r\n",
        "  test_data = CustomImageDataset(test_data.to(torch.float32), test_labels, transforms=val_trans)\r\n",
        "\r\n",
        "  # Assign client modes\r\n",
        "  clients = [Client(ConvNet, lambda x : torch.optim.SGD(x, lr=0.1, momentum=0.9), client_data[i], idnum=i) \r\n",
        "            for i, dat in enumerate(client_data)]\r\n",
        "  client_indx = np.random.permutation(len(clients))\r\n",
        "  offset = 0\r\n",
        "  adv_random = client_indx[0:N_ADV_RANDOM]\r\n",
        "  offset += N_ADV_RANDOM\r\n",
        "  adv_opp = client_indx[offset:offset + N_ADV_OPP]\r\n",
        "  offset += N_ADV_OPP\r\n",
        "  adv_swap = client_indx[offset:offset+N_ADV_SWAP]\r\n",
        "  offset += N_ADV_SWAP\r\n",
        "  adv_idx = np.concatenate((adv_random,adv_opp,adv_swap)).tolist()\r\n",
        "  for i in adv_random:\r\n",
        "    clients[i].client_mode = 'random'\r\n",
        "\r\n",
        "  for i in adv_opp:\r\n",
        "    clients[i].client_mode = 'opposite'\r\n",
        "\r\n",
        "  for i in adv_swap:\r\n",
        "    clients[i].client_mode = 'swap'\r\n",
        "\r\n",
        "  # print out each client and its mode\r\n",
        "  for idx, client in enumerate(clients):\r\n",
        "    print('{}: {}'.format(idx, client.client_mode))\r\n",
        "\r\n",
        "  server = Server(ConvNet, test_data)\r\n",
        "  weights = np.ones(len(clients))\r\n",
        "  for round in range(TOTAL_ROUND):\r\n",
        "    if round == 0:\r\n",
        "      for client in clients:\r\n",
        "        client.synchronize_with_server(server)\r\n",
        "    \r\n",
        "    \r\n",
        "    participating_clients = server.select_clients(clients, frac=1.0)\r\n",
        "\r\n",
        "    for client in participating_clients:\r\n",
        "        train_stats = client.compute_weight_update(epochs=1)\r\n",
        "        client.reset()\r\n",
        "      \r\n",
        "    if round + 1 == DETECT_ROUND:\r\n",
        "        # generate feature matrix for clustering\r\n",
        "        client_dW_dicts = [client.dW for client in clients]\r\n",
        "        feature_matrix = generate_feature_matrix(client_dW_dicts)\r\n",
        "\r\n",
        "        # detect adversary using clustering\r\n",
        "        clustering_label = server.detect_adversary(feature_matrix, esp, min_samples, metric)\r\n",
        "        adv_idx_label = np.argwhere(clustering_label == -1).flatten()\r\n",
        "\r\n",
        "        # update clients by handling adversary detected\r\n",
        "        weights = handle_adversary(adv_idx_label, handle, weights,reg_factor)\r\n",
        "\r\n",
        "    # aggregate weight updates; copy new weights to clients\r\n",
        "    server.aggregate_wieght_updates_weight(clients, weights)\r\n",
        "    server.copy_weights(clients)\r\n",
        "              \r\n",
        "  # evaluate model performance after all the rounds\r\n",
        "  acc_clients = [client.evaluate() for client in clients]\r\n",
        "\r\n",
        "  acc_s = []\r\n",
        "  for i, acc in enumerate(acc_clients):\r\n",
        "    if i not in adv_idx:\r\n",
        "      acc_s.append(acc)\r\n",
        "\r\n",
        "  model_performance[handle][trial] = np.mean(np.array(acc_s)) # evaluation result\r\n",
        "  print(\"handle %s, trial %d\"%(handle, trial))\r\n",
        "  print(acc_s)\r\n",
        "print(\"average performance %f\"%(np.mean(model_performance[handle])))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Data split:\n",
            " - Client 0: [  0   0 240 240 240 240 240   0   0   0]\n",
            " - Client 1: [240 240   0   0   0   0   0 240 240 240]\n",
            " - Client 2: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 3: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 4: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 5: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 6: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 7: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 8: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 9: [  0   0 240 240 240 240 240   0   0   0]\n",
            " - Client 10: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 11: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 12: [240 240   0   0   0   0   0 240 240 240]\n",
            " - Client 13: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 14: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 15: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 16: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 17: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 18: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 19: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 20: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 21: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 22: [  0   0 154 240 240 240 240  86   0   0]\n",
            " - Client 23: [ 66 240   0 160 240  80 240 174   0   0]\n",
            " - Client 24: [  0 218   0   0  29   0  86 495 274  98]\n",
            "\n",
            "\n",
            "Data preprocessing: \n",
            " - ToPILImage()\n",
            " - Resize(size=(28, 28), interpolation=PIL.Image.BILINEAR)\n",
            " - ToTensor()\n",
            " - Normalize(mean=(0.06078,), std=(0.1957,))\n",
            "\n",
            "0: normal\n",
            "1: normal\n",
            "2: normal\n",
            "3: swap\n",
            "4: normal\n",
            "5: normal\n",
            "6: normal\n",
            "7: normal\n",
            "8: normal\n",
            "9: normal\n",
            "10: normal\n",
            "11: normal\n",
            "12: normal\n",
            "13: normal\n",
            "14: normal\n",
            "15: swap\n",
            "16: normal\n",
            "17: normal\n",
            "18: normal\n",
            "19: normal\n",
            "20: normal\n",
            "21: normal\n",
            "22: normal\n",
            "23: normal\n",
            "24: swap\n",
            "handle None, trial 0\n",
            "[0.8416666666666667, 0.9041666666666667, 0.8833333333333333, 0.7625, 0.8625, 0.8041666666666667, 0.7708333333333334, 0.8708333333333333, 0.8375, 0.8333333333333334, 0.8041666666666667, 0.875, 0.8833333333333333, 0.7625, 0.8083333333333333, 0.7916666666666666, 0.8083333333333333, 0.8833333333333333, 0.8958333333333334, 0.825, 0.7791666666666667, 0.7666666666666667]\n",
            "Data split:\n",
            " - Client 0: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 1: [240 240   0   0   0   0   0 240 240 240]\n",
            " - Client 2: [  0   0 240 240 240 240 240   0   0   0]\n",
            " - Client 3: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 4: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 5: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 6: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 7: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 8: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 9: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 10: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 11: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 12: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 13: [  0   0 240 240 240 240 240   0   0   0]\n",
            " - Client 14: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 15: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 16: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 17: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 18: [  0 240  95 222 240 240 163   0   0   0]\n",
            " - Client 19: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 20: [240 240   0   0 240   0   0   0 240 240]\n",
            " - Client 21: [191   0   0   0   0  49 240 240 240 240]\n",
            " - Client 22: [240 104   0   0   0   0 240 240 240 136]\n",
            " - Client 23: [140 162   0   0 178   0 240 240 240   0]\n",
            " - Client 24: [  0   0   0   0 108   0 119 736 237   0]\n",
            "\n",
            "\n",
            "Data preprocessing: \n",
            " - ToPILImage()\n",
            " - Resize(size=(28, 28), interpolation=PIL.Image.BILINEAR)\n",
            " - ToTensor()\n",
            " - Normalize(mean=(0.06078,), std=(0.1957,))\n",
            "\n",
            "0: normal\n",
            "1: normal\n",
            "2: normal\n",
            "3: normal\n",
            "4: normal\n",
            "5: normal\n",
            "6: swap\n",
            "7: normal\n",
            "8: swap\n",
            "9: normal\n",
            "10: normal\n",
            "11: normal\n",
            "12: normal\n",
            "13: normal\n",
            "14: normal\n",
            "15: normal\n",
            "16: normal\n",
            "17: normal\n",
            "18: normal\n",
            "19: normal\n",
            "20: normal\n",
            "21: normal\n",
            "22: normal\n",
            "23: normal\n",
            "24: swap\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "handle None, trial 1\n",
            "[0.8916666666666667, 0.9, 0.8208333333333333, 0.8416666666666667, 0.9041666666666667, 0.8208333333333333, 0.7958333333333333, 0.8333333333333334, 0.8458333333333333, 0.8791666666666667, 0.8208333333333333, 0.825, 0.85, 0.8666666666666667, 0.8, 0.8833333333333333, 0.8041666666666667, 0.8666666666666667, 0.8625, 0.8833333333333333, 0.8416666666666667, 0.8166666666666667]\n",
            "Data split:\n",
            " - Client 0: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 1: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 2: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 3: [  0   0 240 240 240 240 240   0   0   0]\n",
            " - Client 4: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 5: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 6: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 7: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 8: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 9: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 10: [240 240   0   0   0   0   0 240 240 240]\n",
            " - Client 11: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 12: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 13: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 14: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 15: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 16: [  0   0 118 240 240 240 240 122   0   0]\n",
            " - Client 17: [  0 240   0 240 240 240 240   0   0   0]\n",
            " - Client 18: [ 74 204   0 183 240 240 152   0   0 107]\n",
            " - Client 19: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 20: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 21: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 22: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 23: [  0   0   0   0 223 110 387 240 240   0]\n",
            " - Client 24: [  0   0   0   0   0   0  66 819 315   0]\n",
            "\n",
            "\n",
            "Data preprocessing: \n",
            " - ToPILImage()\n",
            " - Resize(size=(28, 28), interpolation=PIL.Image.BILINEAR)\n",
            " - ToTensor()\n",
            " - Normalize(mean=(0.06078,), std=(0.1957,))\n",
            "\n",
            "0: normal\n",
            "1: normal\n",
            "2: swap\n",
            "3: normal\n",
            "4: normal\n",
            "5: normal\n",
            "6: swap\n",
            "7: normal\n",
            "8: normal\n",
            "9: normal\n",
            "10: normal\n",
            "11: normal\n",
            "12: normal\n",
            "13: normal\n",
            "14: normal\n",
            "15: swap\n",
            "16: normal\n",
            "17: normal\n",
            "18: normal\n",
            "19: normal\n",
            "20: normal\n",
            "21: normal\n",
            "22: normal\n",
            "23: normal\n",
            "24: normal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "handle None, trial 2\n",
            "[0.8583333333333333, 0.8458333333333333, 0.9125, 0.8416666666666667, 0.9, 0.8666666666666667, 0.825, 0.8458333333333333, 0.8208333333333333, 0.8833333333333333, 0.8541666666666666, 0.8583333333333333, 0.8291666666666667, 0.9, 0.8541666666666666, 0.875, 0.8791666666666667, 0.8958333333333334, 0.8875, 0.8958333333333334, 0.8458333333333333, 0.8458333333333333]\n",
            "Data split:\n",
            " - Client 0: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 1: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 2: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 3: [240 240   0   0   0   0   0 240 240 240]\n",
            " - Client 4: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 5: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 6: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 7: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 8: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 9: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 10: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 11: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 12: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 13: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 14: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 15: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 16: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 17: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 18: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 19: [240 240 240 209   0   0   0   0  31 240]\n",
            " - Client 20: [  2 238   0   0   0 240 240 240   0 240]\n",
            " - Client 21: [  0 240 240 240 240   0   0   0   0 240]\n",
            " - Client 22: [  0   0 240 240  96 240 240 144   0   0]\n",
            " - Client 23: [  0 240  91 240   0 240  93  56   0 240]\n",
            " - Client 24: [  0 292 293 439   0  68   0   0   0 108]\n",
            "\n",
            "\n",
            "Data preprocessing: \n",
            " - ToPILImage()\n",
            " - Resize(size=(28, 28), interpolation=PIL.Image.BILINEAR)\n",
            " - ToTensor()\n",
            " - Normalize(mean=(0.06078,), std=(0.1957,))\n",
            "\n",
            "0: normal\n",
            "1: normal\n",
            "2: normal\n",
            "3: normal\n",
            "4: normal\n",
            "5: swap\n",
            "6: normal\n",
            "7: normal\n",
            "8: normal\n",
            "9: normal\n",
            "10: normal\n",
            "11: swap\n",
            "12: normal\n",
            "13: normal\n",
            "14: normal\n",
            "15: swap\n",
            "16: normal\n",
            "17: normal\n",
            "18: normal\n",
            "19: normal\n",
            "20: normal\n",
            "21: normal\n",
            "22: normal\n",
            "23: normal\n",
            "24: normal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "handle None, trial 3\n",
            "[0.6083333333333333, 0.48333333333333334, 0.4791666666666667, 0.6666666666666666, 0.4791666666666667, 0.4583333333333333, 0.4791666666666667, 0.5625, 0.5666666666666667, 0.4666666666666667, 0.6208333333333333, 0.49583333333333335, 0.4041666666666667, 0.6291666666666667, 0.6, 0.5083333333333333, 0.6458333333333334, 0.5875, 0.49583333333333335, 0.3625, 0.49166666666666664, 0.49583333333333335]\n",
            "Data split:\n",
            " - Client 0: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 1: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 2: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 3: [  0   0 240 240 240 240 240   0   0   0]\n",
            " - Client 4: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 5: [  0   0 240 240 240 240 240   0   0   0]\n",
            " - Client 6: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 7: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 8: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 9: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 10: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 11: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 12: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 13: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 14: [240 240   0   0   0   0   0 240 240 240]\n",
            " - Client 15: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 16: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 17: [  0   0 240 240 240 240 240   0   0   0]\n",
            " - Client 18: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 19: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 20: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 21: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 22: [240 240  13   0   0  72 121 240 240  34]\n",
            " - Client 23: [ 97 240 100 271 240   0   0 240  12   0]\n",
            " - Client 24: [  0 531   0 147 266   0   0 256   0   0]\n",
            "\n",
            "\n",
            "Data preprocessing: \n",
            " - ToPILImage()\n",
            " - Resize(size=(28, 28), interpolation=PIL.Image.BILINEAR)\n",
            " - ToTensor()\n",
            " - Normalize(mean=(0.06078,), std=(0.1957,))\n",
            "\n",
            "0: normal\n",
            "1: normal\n",
            "2: normal\n",
            "3: normal\n",
            "4: normal\n",
            "5: normal\n",
            "6: normal\n",
            "7: normal\n",
            "8: normal\n",
            "9: normal\n",
            "10: normal\n",
            "11: normal\n",
            "12: normal\n",
            "13: normal\n",
            "14: normal\n",
            "15: normal\n",
            "16: normal\n",
            "17: normal\n",
            "18: swap\n",
            "19: normal\n",
            "20: swap\n",
            "21: normal\n",
            "22: swap\n",
            "23: normal\n",
            "24: normal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "handle None, trial 4\n",
            "[0.8833333333333333, 0.8291666666666667, 0.9125, 0.8666666666666667, 0.8708333333333333, 0.8791666666666667, 0.9, 0.9125, 0.9208333333333333, 0.9166666666666666, 0.9, 0.8791666666666667, 0.8875, 0.9041666666666667, 0.9, 0.8625, 0.95, 0.8916666666666667, 0.9041666666666667, 0.8916666666666667, 0.875, 0.9125]\n",
            "average performance 0.792424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QydmUeQTqiZT"
      },
      "source": [
        "**Experiment 1.3**: Opposite Attack, None detect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c03EAejHqliQ",
        "outputId": "01102c30-242d-4ce8-ab5e-4d0a257f0306"
      },
      "source": [
        "# hyperparameters\r\n",
        "N_CLIENT = 25\r\n",
        "N_ADV_RANDOM = 0\r\n",
        "N_ADV_OPP = 3\r\n",
        "N_ADV_SWAP = 0\r\n",
        "\r\n",
        "# hyperparemeters\r\n",
        "TOTAL_TRIAL = 5\r\n",
        "TOTAL_ROUND = 30\r\n",
        "DETECT_ROUND = 10\r\n",
        "\r\n",
        "# ADV_HANDLE = [None, 'remove', 'reg']\r\n",
        "handle = None\r\n",
        "\r\n",
        "esp = 0.8\r\n",
        "min_samples =2\r\n",
        "reg_factor = 0.1\r\n",
        "metric = 'cosine'\r\n",
        "cfl_stats = ExperimentLogger()\r\n",
        "model_performance = defaultdict(lambda: [None] * TOTAL_TRIAL)\r\n",
        "\r\n",
        "for trial in range(TOTAL_TRIAL):\r\n",
        "  data = datasets.MNIST(root='./',download=True)\r\n",
        "  train_frac = 0.5\r\n",
        "  test_frac = 0.2 \r\n",
        "  train_num = int(train_frac * len(data))\r\n",
        "  test_num = int(test_frac * len(data))\r\n",
        "  idcs = np.random.permutation(len(data))\r\n",
        "  train_idcs, test_idcs = idcs[:train_num], idcs[train_num:train_num + test_num]\r\n",
        "  train_labels = data.train_labels.numpy()\r\n",
        "  clients_split = split_image_data(data.train_data[train_idcs], train_labels[train_idcs], n_clients=N_CLIENT, classes_per_client=5,balancedness=1)\r\n",
        "  train_trans, val_trans = get_default_data_transforms(\"EMNIST\")\r\n",
        "  client_data = [CustomImageDataset(clients_split[i][0].to(torch.float32), clients_split[i][1],transforms=train_trans ) for i in range(len(clients_split))]\r\n",
        "\r\n",
        "  test_data = data.test_data[train_num:train_num+test_num]\r\n",
        "  test_labels = train_labels[train_num:train_num+test_num]\r\n",
        "  test_data = CustomImageDataset(test_data.to(torch.float32), test_labels, transforms=val_trans)\r\n",
        "\r\n",
        "  # Assign client modes\r\n",
        "  clients = [Client(ConvNet, lambda x : torch.optim.SGD(x, lr=0.1, momentum=0.9), client_data[i], idnum=i) \r\n",
        "            for i, dat in enumerate(client_data)]\r\n",
        "  client_indx = np.random.permutation(len(clients))\r\n",
        "  offset = 0\r\n",
        "  adv_random = client_indx[0:N_ADV_RANDOM]\r\n",
        "  offset += N_ADV_RANDOM\r\n",
        "  adv_opp = client_indx[offset:offset + N_ADV_OPP]\r\n",
        "  offset += N_ADV_OPP\r\n",
        "  adv_swap = client_indx[offset:offset+N_ADV_SWAP]\r\n",
        "  offset += N_ADV_SWAP\r\n",
        "  adv_idx = np.concatenate((adv_random,adv_opp,adv_swap)).tolist()\r\n",
        "  for i in adv_random:\r\n",
        "    clients[i].client_mode = 'random'\r\n",
        "\r\n",
        "  for i in adv_opp:\r\n",
        "    clients[i].client_mode = 'opposite'\r\n",
        "\r\n",
        "  for i in adv_swap:\r\n",
        "    clients[i].client_mode = 'swap'\r\n",
        "\r\n",
        "  # print out each client and its mode\r\n",
        "  for idx, client in enumerate(clients):\r\n",
        "    print('{}: {}'.format(idx, client.client_mode))\r\n",
        "\r\n",
        "  server = Server(ConvNet, test_data)\r\n",
        "  weights = np.ones(len(clients))\r\n",
        "  for round in range(TOTAL_ROUND):\r\n",
        "    if round == 0:\r\n",
        "      for client in clients:\r\n",
        "        client.synchronize_with_server(server)\r\n",
        "    \r\n",
        "    \r\n",
        "    participating_clients = server.select_clients(clients, frac=1.0)\r\n",
        "\r\n",
        "    for client in participating_clients:\r\n",
        "        train_stats = client.compute_weight_update(epochs=1)\r\n",
        "        client.reset()\r\n",
        "      \r\n",
        "    if round + 1 == DETECT_ROUND:\r\n",
        "        # generate feature matrix for clustering\r\n",
        "        client_dW_dicts = [client.dW for client in clients]\r\n",
        "        feature_matrix = generate_feature_matrix(client_dW_dicts)\r\n",
        "\r\n",
        "        # detect adversary using clustering\r\n",
        "        clustering_label = server.detect_adversary(feature_matrix, esp, min_samples, metric)\r\n",
        "        adv_idx_label = np.argwhere(clustering_label == -1).flatten()\r\n",
        "\r\n",
        "        # update clients by handling adversary detected\r\n",
        "        weights = handle_adversary(adv_idx_label, handle, weights,reg_factor)\r\n",
        "\r\n",
        "    # aggregate weight updates; copy new weights to clients\r\n",
        "    server.aggregate_wieght_updates_weight(clients, weights)\r\n",
        "    server.copy_weights(clients)\r\n",
        "              \r\n",
        "  # evaluate model performance after all the rounds\r\n",
        "  acc_clients = [client.evaluate() for client in clients]\r\n",
        "\r\n",
        "  acc_s = []\r\n",
        "  for i, acc in enumerate(acc_clients):\r\n",
        "    if i not in adv_idx:\r\n",
        "      acc_s.append(acc)\r\n",
        "\r\n",
        "  model_performance[handle][trial] = np.mean(np.array(acc_s)) # evaluation result\r\n",
        "  print(\"handle %s, trial %d\"%(handle, trial))\r\n",
        "  print(acc_s)\r\n",
        "print(\"average performance %f\"%(np.mean(model_performance[handle])))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Data split:\n",
            " - Client 0: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 1: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 2: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 3: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 4: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 5: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 6: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 7: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 8: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 9: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 10: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 11: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 12: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 13: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 14: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 15: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 16: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 17: [240 240   0   0   0   0   0 240 240 240]\n",
            " - Client 18: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 19: [ 32 240 240 116   0   0   0 240  92 240]\n",
            " - Client 20: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 21: [  0 240 240 240 240   0   0   0   0 240]\n",
            " - Client 22: [  0 240 240 240 149   0 240  19   0  72]\n",
            " - Client 23: [  0 291 240 240  62 240 127   0   0   0]\n",
            " - Client 24: [  0 211  69 341   0 579   0   0   0   0]\n",
            "\n",
            "\n",
            "Data preprocessing: \n",
            " - ToPILImage()\n",
            " - Resize(size=(28, 28), interpolation=PIL.Image.BILINEAR)\n",
            " - ToTensor()\n",
            " - Normalize(mean=(0.06078,), std=(0.1957,))\n",
            "\n",
            "0: normal\n",
            "1: normal\n",
            "2: normal\n",
            "3: normal\n",
            "4: normal\n",
            "5: normal\n",
            "6: normal\n",
            "7: opposite\n",
            "8: normal\n",
            "9: normal\n",
            "10: normal\n",
            "11: normal\n",
            "12: normal\n",
            "13: normal\n",
            "14: normal\n",
            "15: normal\n",
            "16: normal\n",
            "17: normal\n",
            "18: normal\n",
            "19: normal\n",
            "20: normal\n",
            "21: opposite\n",
            "22: opposite\n",
            "23: normal\n",
            "24: normal\n",
            "handle None, trial 0\n",
            "[0.8583333333333333, 0.8416666666666667, 0.775, 0.8708333333333333, 0.875, 0.875, 0.8791666666666667, 0.8416666666666667, 0.8125, 0.8583333333333333, 0.8208333333333333, 0.8666666666666667, 0.8958333333333334, 0.875, 0.8166666666666667, 0.85, 0.8791666666666667, 0.8208333333333333, 0.8708333333333333, 0.8, 0.8458333333333333, 0.7791666666666667]\n",
            "Data split:\n",
            " - Client 0: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 1: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 2: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 3: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 4: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 5: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 6: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 7: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 8: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 9: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 10: [240 240   0   0   0   0   0 240 240 240]\n",
            " - Client 11: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 12: [  0   0 240 240 240 240 240   0   0   0]\n",
            " - Client 13: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 14: [240 240   0   0   0   0   0 240 240 240]\n",
            " - Client 15: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 16: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 17: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 18: [  0   0   0 240 240  21 240 240  51 168]\n",
            " - Client 19: [240 240  32   0   0   0 240 208   0 240]\n",
            " - Client 20: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 21: [116   0 240 240 240   0 124   0   0 240]\n",
            " - Client 22: [240 240 240 240  87   0   0   0   0 153]\n",
            " - Client 23: [240 460 240 240   0   0   0   0   0  20]\n",
            " - Client 24: [196 325 207 472   0   0   0   0   0   0]\n",
            "\n",
            "\n",
            "Data preprocessing: \n",
            " - ToPILImage()\n",
            " - Resize(size=(28, 28), interpolation=PIL.Image.BILINEAR)\n",
            " - ToTensor()\n",
            " - Normalize(mean=(0.06078,), std=(0.1957,))\n",
            "\n",
            "0: normal\n",
            "1: normal\n",
            "2: normal\n",
            "3: normal\n",
            "4: normal\n",
            "5: normal\n",
            "6: normal\n",
            "7: normal\n",
            "8: normal\n",
            "9: normal\n",
            "10: normal\n",
            "11: opposite\n",
            "12: normal\n",
            "13: normal\n",
            "14: normal\n",
            "15: opposite\n",
            "16: normal\n",
            "17: opposite\n",
            "18: normal\n",
            "19: normal\n",
            "20: normal\n",
            "21: normal\n",
            "22: normal\n",
            "23: normal\n",
            "24: normal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "handle None, trial 1\n",
            "[0.75, 0.8458333333333333, 0.65, 0.6625, 0.8083333333333333, 0.7791666666666667, 0.675, 0.8416666666666667, 0.6791666666666667, 0.8416666666666667, 0.75, 0.7375, 0.7916666666666666, 0.8208333333333333, 0.7, 0.775, 0.8541666666666666, 0.8541666666666666, 0.8333333333333334, 0.8666666666666667, 0.8708333333333333, 0.875]\n",
            "Data split:\n",
            " - Client 0: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 1: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 2: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 3: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 4: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 5: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 6: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 7: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 8: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 9: [  0   0 240 240 240 240 240   0   0   0]\n",
            " - Client 10: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 11: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 12: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 13: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 14: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 15: [240 240 240 176 240  64   0   0   0   0]\n",
            " - Client 16: [240 240   0   0   0   0   0 240 240 240]\n",
            " - Client 17: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 18: [240 240 240   0 240   0   0   0   0 240]\n",
            " - Client 19: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 20: [144 240  96   0   0   0   0 240 240 240]\n",
            " - Client 21: [  0 193  18   0  29   0 240 240 240 240]\n",
            " - Client 22: [  0   0   0   0  23 240 240 240 240 217]\n",
            " - Client 23: [  0   0   0   0   0 344 240 240 240 136]\n",
            " - Client 24: [  0   0   0   0   0 119 369 162 550   0]\n",
            "\n",
            "\n",
            "Data preprocessing: \n",
            " - ToPILImage()\n",
            " - Resize(size=(28, 28), interpolation=PIL.Image.BILINEAR)\n",
            " - ToTensor()\n",
            " - Normalize(mean=(0.06078,), std=(0.1957,))\n",
            "\n",
            "0: normal\n",
            "1: normal\n",
            "2: normal\n",
            "3: opposite\n",
            "4: normal\n",
            "5: normal\n",
            "6: normal\n",
            "7: opposite\n",
            "8: normal\n",
            "9: normal\n",
            "10: normal\n",
            "11: normal\n",
            "12: normal\n",
            "13: normal\n",
            "14: normal\n",
            "15: normal\n",
            "16: normal\n",
            "17: normal\n",
            "18: normal\n",
            "19: normal\n",
            "20: normal\n",
            "21: normal\n",
            "22: normal\n",
            "23: opposite\n",
            "24: normal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "handle None, trial 2\n",
            "[0.8583333333333333, 0.875, 0.8833333333333333, 0.925, 0.9, 0.8875, 0.9166666666666666, 0.8375, 0.9291666666666667, 0.8708333333333333, 0.8166666666666667, 0.9083333333333333, 0.8541666666666666, 0.8958333333333334, 0.8666666666666667, 0.8416666666666667, 0.85, 0.875, 0.8958333333333334, 0.9125, 0.8583333333333333, 0.8625]\n",
            "Data split:\n",
            " - Client 0: [  0   0 240 240 240 240 240   0   0   0]\n",
            " - Client 1: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 2: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 3: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 4: [  0   0 240 240 240 240 240   0   0   0]\n",
            " - Client 5: [240 240   0   0   0   0   0 240 240 240]\n",
            " - Client 6: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 7: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 8: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 9: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 10: [240   0   0   0   0   0 240 240 240 240]\n",
            " - Client 11: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 12: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 13: [240 240 240 240 240   0   0   0   0   0]\n",
            " - Client 14: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 15: [  0   0   0   0 240 240 240 240 240   0]\n",
            " - Client 16: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 17: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 18: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 19: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 20: [  0   0   0   0 225 240 240 240 240  15]\n",
            " - Client 21: [240 240 121 240   0 133 226   0   0   0]\n",
            " - Client 22: [  0 240   0 128   0   0 240 240 240 112]\n",
            " - Client 23: [240 170   0   0   0   0 104 240 206 240]\n",
            " - Client 24: [103   0   0   0   0   0   0 539 103 455]\n",
            "\n",
            "\n",
            "Data preprocessing: \n",
            " - ToPILImage()\n",
            " - Resize(size=(28, 28), interpolation=PIL.Image.BILINEAR)\n",
            " - ToTensor()\n",
            " - Normalize(mean=(0.06078,), std=(0.1957,))\n",
            "\n",
            "0: normal\n",
            "1: normal\n",
            "2: opposite\n",
            "3: normal\n",
            "4: opposite\n",
            "5: normal\n",
            "6: normal\n",
            "7: normal\n",
            "8: normal\n",
            "9: normal\n",
            "10: normal\n",
            "11: normal\n",
            "12: normal\n",
            "13: normal\n",
            "14: normal\n",
            "15: normal\n",
            "16: opposite\n",
            "17: normal\n",
            "18: normal\n",
            "19: normal\n",
            "20: normal\n",
            "21: normal\n",
            "22: normal\n",
            "23: normal\n",
            "24: normal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "handle None, trial 3\n",
            "[0.6541666666666667, 0.7958333333333333, 0.825, 0.8791666666666667, 0.6416666666666667, 0.6708333333333333, 0.8, 0.8375, 0.8208333333333333, 0.8458333333333333, 0.6875, 0.6958333333333333, 0.6583333333333333, 0.6916666666666667, 0.675, 0.8208333333333333, 0.7208333333333333, 0.7291666666666666, 0.7375, 0.8291666666666667, 0.8458333333333333, 0.7666666666666667]\n",
            "Data split:\n",
            " - Client 0: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 1: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 2: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 3: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 4: [  0   0 240 240 240 240 240   0   0   0]\n",
            " - Client 5: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 6: [  0   0   0   0   0 240 240 240 240 240]\n",
            " - Client 7: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 8: [240 240   0   0   0   0   0 240 240 240]\n",
            " - Client 9: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 10: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 11: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 12: [  0   0 240 240 240 240 240   0   0   0]\n",
            " - Client 13: [  0 240 240 240 240 240   0   0   0   0]\n",
            " - Client 14: [  0   0   0 240 240 240 240 240   0   0]\n",
            " - Client 15: [240 240 240 240   0   0   0   0   0 240]\n",
            " - Client 16: [  0 240 240  71 240 240 169   0   0   0]\n",
            " - Client 17: [240 240 240   0 240   0   0   0   0 240]\n",
            " - Client 18: [240 240 240   0   0   0   0   0 240 240]\n",
            " - Client 19: [  0 240  63   0 240 240 240 177   0   0]\n",
            " - Client 20: [  0 240   0   0 240  32 240 240 208   0]\n",
            " - Client 21: [  0   0   0   0 240   0 240 240 240 240]\n",
            " - Client 22: [240 126   0   0   0   0 198 240 240 156]\n",
            " - Client 23: [480 208   0   0  20   0   0 252 240   0]\n",
            " - Client 24: [ 83   0   0   0   0   0   0 317 800   0]\n",
            "\n",
            "\n",
            "Data preprocessing: \n",
            " - ToPILImage()\n",
            " - Resize(size=(28, 28), interpolation=PIL.Image.BILINEAR)\n",
            " - ToTensor()\n",
            " - Normalize(mean=(0.06078,), std=(0.1957,))\n",
            "\n",
            "0: normal\n",
            "1: normal\n",
            "2: normal\n",
            "3: normal\n",
            "4: opposite\n",
            "5: normal\n",
            "6: normal\n",
            "7: normal\n",
            "8: normal\n",
            "9: normal\n",
            "10: normal\n",
            "11: normal\n",
            "12: opposite\n",
            "13: normal\n",
            "14: normal\n",
            "15: normal\n",
            "16: opposite\n",
            "17: normal\n",
            "18: normal\n",
            "19: normal\n",
            "20: normal\n",
            "21: normal\n",
            "22: normal\n",
            "23: normal\n",
            "24: normal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "handle None, trial 4\n",
            "[0.8458333333333333, 0.9041666666666667, 0.9541666666666667, 0.8333333333333334, 0.8083333333333333, 0.8583333333333333, 0.875, 0.9541666666666667, 0.9291666666666667, 0.8666666666666667, 0.7708333333333334, 0.7583333333333333, 0.7958333333333333, 0.8958333333333334, 0.875, 0.925, 0.8416666666666667, 0.8833333333333333, 0.8916666666666667, 0.8583333333333333, 0.9458333333333333, 0.9]\n",
            "average performance 0.827197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh8HB4Wt8rBS"
      },
      "source": [
        "**`Experiement 2.1: Random, Remove`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh2R6bzR8s2a"
      },
      "source": [
        "# hyperparameters\r\n",
        "N_CLIENT = 25\r\n",
        "N_ADV_RANDOM = 3\r\n",
        "N_ADV_OPP = 0\r\n",
        "N_ADV_SWAP = 0\r\n",
        "\r\n",
        "# hyperparemeters\r\n",
        "TOTAL_TRIAL = 5\r\n",
        "TOTAL_ROUND = 30\r\n",
        "DETECT_ROUND = 10\r\n",
        "\r\n",
        "# ADV_HANDLE = [None, 'remove', 'reg']\r\n",
        "handle = 'remove'\r\n",
        "\r\n",
        "esp = 0.8\r\n",
        "min_samples =4\r\n",
        "reg_factor = 0.1\r\n",
        "metric = 'cosine'\r\n",
        "cfl_stats = ExperimentLogger()\r\n",
        "model_performance = defaultdict(lambda: [None] * TOTAL_TRIAL)\r\n",
        "\r\n",
        "for trial in range(TOTAL_TRIAL):\r\n",
        "  data = datasets.MNIST(root='./',download=True)\r\n",
        "  train_frac = 0.5\r\n",
        "  test_frac = 0.2 \r\n",
        "  train_num = int(train_frac * len(data))\r\n",
        "  test_num = int(test_frac * len(data))\r\n",
        "  idcs = np.random.permutation(len(data))\r\n",
        "  train_idcs, test_idcs = idcs[:train_num], idcs[train_num:train_num + test_num]\r\n",
        "  train_labels = data.train_labels.numpy()\r\n",
        "  clients_split = split_image_data(data.train_data[train_idcs], train_labels[train_idcs], n_clients=N_CLIENT, classes_per_client=5,balancedness=1)\r\n",
        "  train_trans, val_trans = get_default_data_transforms(\"EMNIST\")\r\n",
        "  client_data = [CustomImageDataset(clients_split[i][0].to(torch.float32), clients_split[i][1],transforms=train_trans ) for i in range(len(clients_split))]\r\n",
        "\r\n",
        "  test_data = data.test_data[train_num:train_num+test_num]\r\n",
        "  test_labels = train_labels[train_num:train_num+test_num]\r\n",
        "  test_data = CustomImageDataset(test_data.to(torch.float32), test_labels, transforms=val_trans)\r\n",
        "\r\n",
        "  # Assign client modes\r\n",
        "  clients = [Client(ConvNet, lambda x : torch.optim.SGD(x, lr=0.1, momentum=0.9), client_data[i], idnum=i) \r\n",
        "            for i, dat in enumerate(client_data)]\r\n",
        "  client_indx = np.random.permutation(len(clients))\r\n",
        "  offset = 0\r\n",
        "  adv_random = client_indx[0:N_ADV_RANDOM]\r\n",
        "  offset += N_ADV_RANDOM\r\n",
        "  adv_opp = client_indx[offset:offset + N_ADV_OPP]\r\n",
        "  offset += N_ADV_OPP\r\n",
        "  adv_swap = client_indx[offset:offset+N_ADV_SWAP]\r\n",
        "  offset += N_ADV_SWAP\r\n",
        "  adv_idx = np.concatenate((adv_random,adv_opp,adv_swap)).tolist()\r\n",
        "  for i in adv_random:\r\n",
        "    clients[i].client_mode = 'random'\r\n",
        "\r\n",
        "  for i in adv_opp:\r\n",
        "    clients[i].client_mode = 'opposite'\r\n",
        "\r\n",
        "  for i in adv_swap:\r\n",
        "    clients[i].client_mode = 'swap'\r\n",
        "\r\n",
        "  # print out each client and its mode\r\n",
        "  for idx, client in enumerate(clients):\r\n",
        "    print('{}: {}'.format(idx, client.client_mode))\r\n",
        "\r\n",
        "  server = Server(ConvNet, test_data)\r\n",
        "  weights = np.ones(len(clients))\r\n",
        "  for round in range(TOTAL_ROUND):\r\n",
        "    if round == 0:\r\n",
        "      for client in clients:\r\n",
        "        client.synchronize_with_server(server)\r\n",
        "    \r\n",
        "    \r\n",
        "    participating_clients = server.select_clients(clients, frac=1.0)\r\n",
        "\r\n",
        "    for client in participating_clients:\r\n",
        "        train_stats = client.compute_weight_update(epochs=1)\r\n",
        "        client.reset()\r\n",
        "      \r\n",
        "    if round + 1 == DETECT_ROUND:\r\n",
        "        # generate feature matrix for clustering\r\n",
        "        client_dW_dicts = [client.dW for client in clients]\r\n",
        "        feature_matrix = generate_feature_matrix(client_dW_dicts)\r\n",
        "\r\n",
        "        # detect adversary using clustering\r\n",
        "        clustering_label = server.detect_adversary(feature_matrix, esp, min_samples, metric)\r\n",
        "        adv_idx_label = np.argwhere(clustering_label == -1).flatten()\r\n",
        "\r\n",
        "        # update clients by handling adversary detected\r\n",
        "        weights = handle_adversary(adv_idx_label, handle, weights,reg_factor)\r\n",
        "\r\n",
        "    # aggregate weight updates; copy new weights to clients\r\n",
        "    server.aggregate_wieght_updates_weight(clients, weights)\r\n",
        "    server.copy_weights(clients)\r\n",
        "              \r\n",
        "  # evaluate model performance after all the rounds\r\n",
        "  acc_clients = [client.evaluate() for client in clients]\r\n",
        "\r\n",
        "  acc_s = []\r\n",
        "  for i, acc in enumerate(acc_clients):\r\n",
        "    if i not in adv_idx:\r\n",
        "      acc_s.append(acc)\r\n",
        "\r\n",
        "  model_performance[handle][trial] = np.mean(np.array(acc_s)) # evaluation result\r\n",
        "  print(\"handle %s, trial %d\"%(handle, trial))\r\n",
        "  print(acc_s)\r\n",
        "print(\"average performance %f\"%(np.mean(model_performance[handle])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4qevFpIOv9i"
      },
      "source": [
        "## Experiment A: Model Performance\n",
        "Compare model that does handle adversary and model that does NOT handle adversary.\n",
        "\n",
        "Same TOTAL_ROUND -> Different accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZbUknB2Ov9j"
      },
      "source": [
        "# hyperparemeters\n",
        "TOTAL_TRIAL = 30\n",
        "TOTAL_ROUND = 20\n",
        "DETECT_ROUND = 5\n",
        "\n",
        "ESP = 0.5\n",
        "MIN_SAMPLES = 2\n",
        "METRIC = 'l2'\n",
        "\n",
        "ADV_HANDLE = [None, 'remove', 'reg']\n",
        "\n",
        "model_performance = defaultdict(lambda: [None] * TOTAL_TRIAL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ahiGZaBOv9j"
      },
      "source": [
        "for handle in ADV_HANDLE:\n",
        "    for trial in range(TOTAL_TRIAL):\n",
        "        for round in range(TOTAL_ROUND):\n",
        "            if round == 0:\n",
        "                for client in clients:\n",
        "                    client.synchronize_with_server(server)\n",
        "\n",
        "                participating_clients = server.select_clients(clients, frac=1.0)\n",
        "\n",
        "                for client in participating_clients:\n",
        "                    train_stats = client.compute_weight_update(epochs=1)\n",
        "                    client.reset()\n",
        "\n",
        "                if round + 1 == DETECT_ROUND:\n",
        "                    # generate feature matrix for clustering\n",
        "                    client_dW_dicts = [client.dW for client in clients]\n",
        "                    feature_matrix = generate_feature_matrix(client_dW_dicts)\n",
        "\n",
        "                    # detect adversary using clustering\n",
        "                    detect_adv_idx = server.detect_adversary(feature_matrix, esp, min_samples, metric)\n",
        "\n",
        "                    # update clients by handling adversary detected\n",
        "                    clients = handle_advesary(clients, detect_adv_idx, ADV_HANDLE)\n",
        "\n",
        "                # aggregate weight updates; copy new weights to clients\n",
        "                server.aggregate_weight_updates(clients)\n",
        "                server.copy_weights(clients)\n",
        "                \n",
        "        # evaluate model performance after all the rounds\n",
        "        model_performance[handle][trial] = # evaluation result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2MdT6YtOv9j"
      },
      "source": [
        "# plots\n",
        "# TODO\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "397E7-pjOv9j"
      },
      "source": [
        "## Experiment B: Convergence Rate\n",
        "Compare model that does handle adversary and model that does NOT handle adversary.\n",
        "\n",
        "Same accuracy -> Different round"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMPG9DO0Ov9k"
      },
      "source": [
        "# hyperparemeters\n",
        "TOTAL_TRIAL = 30\n",
        "MAX_ROUND = 50\n",
        "DETECT_ROUND = 5\n",
        "\n",
        "TARGET_ACC = 0.66\n",
        "\n",
        "ESP = 0.5\n",
        "MIN_SAMPLES = 2\n",
        "METRIC = 'l2'\n",
        "\n",
        "ADV_HANDLE = [None, 'remove', 'reg']\n",
        "\n",
        "model_round = defaultdict(lambda: [None] * TOTAL_TRIAL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39n7DCRDOv9k"
      },
      "source": [
        "for handle in ADV_HANDLE:\n",
        "    for trial in range(TOTAL_TRIAL):\n",
        "        for round in range(MAX_ROUND):\n",
        "            if round == 0:\n",
        "                for client in clients:\n",
        "                    client.synchronize_with_server(server)\n",
        "\n",
        "                participating_clients = server.select_clients(clients, frac=1.0)\n",
        "\n",
        "                for client in participating_clients:\n",
        "                    train_stats = client.compute_weight_update(epochs=1)\n",
        "                    client.reset()\n",
        "\n",
        "                if round + 1 == DETECT_ROUND:\n",
        "                    # generate feature matrix for clustering\n",
        "                    client_dW_dicts = [client.dW for client in clients]\n",
        "                    feature_matrix = generate_feature_matrix(client_dW_dicts)\n",
        "\n",
        "                    # detect adversary using clustering\n",
        "                    detect_adv_idx = server.detect_adversary(feature_matrix, esp, min_samples, metric)\n",
        "\n",
        "                    # update clients by handling adversary detected\n",
        "                    clients = handle_advesary(clients, detect_adv_idx, ADV_HANDLE)\n",
        "\n",
        "                # aggregate weight updates; copy new weights to clients\n",
        "                server.aggregate_weight_updates(clients)\n",
        "                server.copy_weights(clients)\n",
        "                \n",
        "            # evaluate model performance after each round\n",
        "            model_performance = # evaluation result\n",
        "            if model_performance >= TARGET_ACC:\n",
        "                model_round[handle][trial] = round + 1\n",
        "                break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ8DWm0DOv9k"
      },
      "source": [
        "# plots\n",
        "# TODO\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VocB8dfpOv9k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7I4tV1-Ov9k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoziMD3AOv9l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt2Cgn_ZOv9l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}