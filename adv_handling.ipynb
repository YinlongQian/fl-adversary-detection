{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "adv_handling.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVJsctDXOv9g"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "from data_utils import CustomImageDataset, split_image_data\n",
        "from data_utils import get_default_data_transforms\n",
        "from models import ConvNet\n",
        "from fl_devices import Server, Client\n",
        "from helper import ExperimentLogger, display_train_stats\n",
        "\n",
        "from sklearn.cluster import AgglomerativeClustering, DBSCAN\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr7jG9NfOv9i"
      },
      "source": [
        "# helper functions\n",
        "\n",
        "# feature_matrix:\n",
        "# each row is flatten dWs from a client\n",
        "# helper functions\n",
        "\n",
        "# detect_adv_idx: adverary indices detected by server\n",
        "# gt_adv_idx: ground-truth indices\n",
        "def check_detect(detect_adv_idx, gt_adv_idx):\n",
        "    intersection = [idx for idx in gt_adv_idx if idx in detect_adv_idx]\n",
        "    if len(intersection) > 0:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "    \n",
        "# feature_matrix:\n",
        "# each row is flatten dWs from a client\n",
        "def generate_feature_matrix(dW_dicts):\n",
        "    with torch.no_grad():\n",
        "        rows = []\n",
        "        \n",
        "        for dW_dict in dW_dicts:\n",
        "            row = torch.empty(0).to(device)\n",
        "            for key, value in dW_dict.items():\n",
        "                row = torch.cat((row, value.flatten()), 0)\n",
        "            rows.append(row)\n",
        "            \n",
        "        matrix = torch.stack(rows, 0)\n",
        "        if device is \"cpu\":\n",
        "            return matrix.numpy()\n",
        "        else:\n",
        "            return matrix.cpu().numpy()\n",
        "        \n",
        "def print_labels(labels):\n",
        "    string = []\n",
        "    for idx, label in enumerate(labels):\n",
        "        string.append(str(idx)+': '+str(label))\n",
        "    print('\\t'.join(string))\n",
        "    \n",
        "def print_outliers(labels):\n",
        "    outlier_idx = np.argwhere(labels == -1).flatten()\n",
        "    print(outlier_idx)\n",
        "    \n",
        "def print_distance(feature_matrix, metric):\n",
        "    distance = pairwise_distances(feature_matrix,metric=metirc)\n",
        "    return distance \n",
        "\n",
        "def handle_adversary(adv_idx, handle, weights, reg_factor):\n",
        "    if handle == None:\n",
        "        return weights\n",
        "    elif handle == 'remove':\n",
        "        weights[adv_idx] = 0\n",
        "        return weights \n",
        "    elif handle == 'reg':\n",
        "        weights[adv_idx] = weights[adv_idx] * reg_factor\n",
        "    return weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70UGDklQSZFj"
      },
      "source": [
        "# hyperparameters\r\n",
        "N_CLIENT = 25\r\n",
        "N_ADV_RANDOM = 3\r\n",
        "N_ADV_OPP = 0\r\n",
        "N_ADV_SWAP = 0\r\n",
        "\r\n",
        "# hyperparemeters\r\n",
        "TOTAL_TRIAL = 5\r\n",
        "TOTAL_ROUND = 40\r\n",
        "DETECT_ROUND = 10\r\n",
        "\r\n",
        "ADV_HANDLE = [None, 'remove', 'reg']\r\n",
        "\r\n",
        "esp = 0.8\r\n",
        "min_samples =2\r\n",
        "reg_factor = 0.1\r\n",
        "metric = 'cosine'\r\n",
        "cfl_stats = ExperimentLogger()\r\n",
        "model_performance = defaultdict(lambda: [None] * TOTAL_TRIAL)\r\n",
        "for handle in ADV_HANDLE:\r\n",
        "  for trial in range(TOTAL_TRIAL):\r\n",
        "    data = datasets.MNIST(root='./',download=True)\r\n",
        "    train_frac = 0.5\r\n",
        "    test_frac = 0.2 \r\n",
        "    train_num = int(train_frac * len(data))\r\n",
        "    test_num = int(test_frac * len(data))\r\n",
        "    idcs = np.random.permutation(len(data))\r\n",
        "    train_idcs, test_idcs = idcs[:train_num], idcs[train_num:train_num + test_num]\r\n",
        "    train_labels = data.train_labels.numpy()\r\n",
        "    clients_split = split_image_data(data.train_data[train_idcs], train_labels[train_idcs], n_clients=N_CLIENT, classes_per_client=5,balancedness=1)\r\n",
        "    train_trans, val_trans = get_default_data_transforms(\"EMNIST\")\r\n",
        "    client_data = [CustomImageDataset(clients_split[i][0].to(torch.float32), clients_split[i][1],transforms=train_trans ) for i in range(len(clients_split))]\r\n",
        "\r\n",
        "    test_data = data.test_data[train_num:train_num+test_num]\r\n",
        "    test_labels = train_labels[train_num:train_num+test_num]\r\n",
        "    test_data = CustomImageDataset(test_data.to(torch.float32), test_labels, transforms=val_trans)\r\n",
        "\r\n",
        "    # Assign client modes\r\n",
        "    clients = [Client(ConvNet, lambda x : torch.optim.SGD(x, lr=0.1, momentum=0.9), client_data[i], idnum=i) \r\n",
        "              for i, dat in enumerate(client_data)]\r\n",
        "    client_indx = np.random.permutation(len(clients))\r\n",
        "    offset = 0\r\n",
        "    adv_random = client_indx[0:N_ADV_RANDOM]\r\n",
        "    offset += N_ADV_RANDOM\r\n",
        "    adv_opp = client_indx[offset:offset + N_ADV_OPP]\r\n",
        "    offset += N_ADV_OPP\r\n",
        "    adv_swap = client_indx[offset:offset+N_ADV_SWAP]\r\n",
        "    offset += N_ADV_SWAP\r\n",
        "    adv_idx = np.concatenate((adv_random,adv_opp,adv_swap)).tolist()\r\n",
        "    for i in adv_random:\r\n",
        "      clients[i].client_mode = 'random'\r\n",
        "\r\n",
        "    for i in adv_opp:\r\n",
        "      clients[i].client_mode = 'opposite'\r\n",
        "\r\n",
        "    for i in adv_swap:\r\n",
        "      clients[i].client_mode = 'swap'\r\n",
        "\r\n",
        "    # print out each client and its mode\r\n",
        "    for idx, client in enumerate(clients):\r\n",
        "      print('{}: {}'.format(idx, client.client_mode))\r\n",
        "\r\n",
        "    server = Server(ConvNet, test_data)\r\n",
        "    weights = np.ones(len(clients))\r\n",
        "    for round in range(TOTAL_ROUND):\r\n",
        "      if round == 0:\r\n",
        "        for client in clients:\r\n",
        "          client.synchronize_with_server(server)\r\n",
        "      \r\n",
        "      \r\n",
        "      participating_clients = server.select_clients(clients, frac=1.0)\r\n",
        "\r\n",
        "      for client in participating_clients:\r\n",
        "          train_stats = client.compute_weight_update(epochs=1)\r\n",
        "          client.reset()\r\n",
        "        \r\n",
        "      if round + 1 == DETECT_ROUND:\r\n",
        "          # generate feature matrix for clustering\r\n",
        "          client_dW_dicts = [client.dW for client in clients]\r\n",
        "          feature_matrix = generate_feature_matrix(client_dW_dicts)\r\n",
        "\r\n",
        "          # detect adversary using clustering\r\n",
        "          clustering_label = server.detect_adversary(feature_matrix, esp, min_samples, metric)\r\n",
        "          adv_idx_label = np.argwhere(clustering_label == -1).flatten()\r\n",
        "\r\n",
        "          # update clients by handling adversary detected\r\n",
        "          clients = handle_advesary(adv_idx_label, ADV_HANDLE, weights,reg_factor)\r\n",
        "\r\n",
        "      # aggregate weight updates; copy new weights to clients\r\n",
        "      server.aggregate_weight_updates_weights(clients, weights)\r\n",
        "      server.copy_weights(clients)\r\n",
        "                \r\n",
        "    # evaluate model performance after all the rounds\r\n",
        "    acc_clients = [client.evaluate() for client in clients]\r\n",
        "\r\n",
        "    acc_s = []\r\n",
        "    for i, acc in enumerate(acc_clients):\r\n",
        "      if i not in adv_idx:\r\n",
        "        acc_s.append(acc)\r\n",
        "  \r\n",
        "    model_performance[handle][trial] = np.mean(np.array(acc_s)) # evaluation result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4qevFpIOv9i"
      },
      "source": [
        "## Experiment A: Model Performance\n",
        "Compare model that does handle adversary and model that does NOT handle adversary.\n",
        "\n",
        "Same TOTAL_ROUND -> Different accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZbUknB2Ov9j"
      },
      "source": [
        "# hyperparemeters\n",
        "TOTAL_TRIAL = 30\n",
        "TOTAL_ROUND = 20\n",
        "DETECT_ROUND = 5\n",
        "\n",
        "ESP = 0.5\n",
        "MIN_SAMPLES = 2\n",
        "METRIC = 'l2'\n",
        "\n",
        "ADV_HANDLE = [None, 'remove', 'reg']\n",
        "\n",
        "model_performance = defaultdict(lambda: [None] * TOTAL_TRIAL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ahiGZaBOv9j"
      },
      "source": [
        "for handle in ADV_HANDLE:\n",
        "    for trial in range(TOTAL_TRIAL):\n",
        "        for round in range(TOTAL_ROUND):\n",
        "            if round == 0:\n",
        "                for client in clients:\n",
        "                    client.synchronize_with_server(server)\n",
        "\n",
        "                participating_clients = server.select_clients(clients, frac=1.0)\n",
        "\n",
        "                for client in participating_clients:\n",
        "                    train_stats = client.compute_weight_update(epochs=1)\n",
        "                    client.reset()\n",
        "\n",
        "                if round + 1 == DETECT_ROUND:\n",
        "                    # generate feature matrix for clustering\n",
        "                    client_dW_dicts = [client.dW for client in clients]\n",
        "                    feature_matrix = generate_feature_matrix(client_dW_dicts)\n",
        "\n",
        "                    # detect adversary using clustering\n",
        "                    detect_adv_idx = server.detect_adversary(feature_matrix, esp, min_samples, metric)\n",
        "\n",
        "                    # update clients by handling adversary detected\n",
        "                    clients = handle_advesary(clients, detect_adv_idx, ADV_HANDLE)\n",
        "\n",
        "                # aggregate weight updates; copy new weights to clients\n",
        "                server.aggregate_weight_updates(clients)\n",
        "                server.copy_weights(clients)\n",
        "                \n",
        "        # evaluate model performance after all the rounds\n",
        "        model_performance[handle][trial] = # evaluation result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2MdT6YtOv9j"
      },
      "source": [
        "# plots\n",
        "# TODO\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "397E7-pjOv9j"
      },
      "source": [
        "## Experiment B: Convergence Rate\n",
        "Compare model that does handle adversary and model that does NOT handle adversary.\n",
        "\n",
        "Same accuracy -> Different round"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMPG9DO0Ov9k"
      },
      "source": [
        "# hyperparemeters\n",
        "TOTAL_TRIAL = 30\n",
        "MAX_ROUND = 50\n",
        "DETECT_ROUND = 5\n",
        "\n",
        "TARGET_ACC = 0.66\n",
        "\n",
        "ESP = 0.5\n",
        "MIN_SAMPLES = 2\n",
        "METRIC = 'l2'\n",
        "\n",
        "ADV_HANDLE = [None, 'remove', 'reg']\n",
        "\n",
        "model_round = defaultdict(lambda: [None] * TOTAL_TRIAL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39n7DCRDOv9k"
      },
      "source": [
        "for handle in ADV_HANDLE:\n",
        "    for trial in range(TOTAL_TRIAL):\n",
        "        for round in range(MAX_ROUND):\n",
        "            if round == 0:\n",
        "                for client in clients:\n",
        "                    client.synchronize_with_server(server)\n",
        "\n",
        "                participating_clients = server.select_clients(clients, frac=1.0)\n",
        "\n",
        "                for client in participating_clients:\n",
        "                    train_stats = client.compute_weight_update(epochs=1)\n",
        "                    client.reset()\n",
        "\n",
        "                if round + 1 == DETECT_ROUND:\n",
        "                    # generate feature matrix for clustering\n",
        "                    client_dW_dicts = [client.dW for client in clients]\n",
        "                    feature_matrix = generate_feature_matrix(client_dW_dicts)\n",
        "\n",
        "                    # detect adversary using clustering\n",
        "                    detect_adv_idx = server.detect_adversary(feature_matrix, esp, min_samples, metric)\n",
        "\n",
        "                    # update clients by handling adversary detected\n",
        "                    clients = handle_advesary(clients, detect_adv_idx, ADV_HANDLE)\n",
        "\n",
        "                # aggregate weight updates; copy new weights to clients\n",
        "                server.aggregate_weight_updates(clients)\n",
        "                server.copy_weights(clients)\n",
        "                \n",
        "            # evaluate model performance after each round\n",
        "            model_performance = # evaluation result\n",
        "            if model_performance >= TARGET_ACC:\n",
        "                model_round[handle][trial] = round + 1\n",
        "                break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ8DWm0DOv9k"
      },
      "source": [
        "# plots\n",
        "# TODO\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VocB8dfpOv9k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7I4tV1-Ov9k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoziMD3AOv9l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt2Cgn_ZOv9l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}